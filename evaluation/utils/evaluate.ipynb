{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đây là template ví dụ template:\n",
    "data_exmp = [\n",
    "    {\n",
    "        \"template\": \"PacketResponder <*> for block <*> terminating\",\n",
    "        \"message\": \"PacketResponder 1 for block blk_1073741825 terminating\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to <*> size <*>\",\n",
    "        \"message\": \"BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:50010 is added to blockpool size 67108864\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"Received block <*> of size <*> from <*>\",\n",
    "        \"message\": \"Received block blk_1073741827 of size 1048576 from 127.0.0.1\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"Receiving block <*> src: <*>:<*> dest: <*>:<*>\",\n",
    "        \"message\": \"Receiving block blk_1073741827 src: 127.0.0.1:50010 dest: 127.0.0.1:50020\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"BLOCK* NameSystem.allocateBlock: <*> <*>\",\n",
    "        \"message\": \"BLOCK* NameSystem.allocateBlock: user1 blk_1073741826\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"Verification succeeded for <*>\",\n",
    "        \"message\": \"Verification succeeded for blk_1073741828\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"Deleting block <*> file <*>\",\n",
    "        \"message\": \"Deleting block blk_1073741829 file /tmp/hadoop/blk_1073741829\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"<*>:<*> Served block <*> to <*>\",\n",
    "        \"message\": \"127.0.0.1:50010 Served block blk_1073741830 to client1\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"<*>:<*>:Got exception while serving <*> to <*>:\",\n",
    "        \"message\": \"127.0.0.1:50010:Got exception while serving blk_1073741831 to client2:\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"BLOCK* NameSystem.delete: <*> is added to invalidSet of <*>:<*>\",\n",
    "        \"message\": \"BLOCK* NameSystem.delete: blk_1073741832 is added to invalidSet of 127.0.0.1:50010\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"<*>:<*> Starting thread to transfer block <*> to <*>:<*>\",\n",
    "        \"message\": \"127.0.0.1:50010 Starting thread to transfer block blk_1073741833 to 127.0.0.1:50011\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"BLOCK* ask <*>:<*> to delete <*>\",\n",
    "        \"message\": \"BLOCK* ask 127.0.0.1:50010 to delete blk_1073741834\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"Received block <*> src: <*>:<*> dest: <*>:<*> of size <*>\",\n",
    "        \"message\": \"Received block blk_1073741835 src: 127.0.0.1:50010 dest: 127.0.0.1:50020 of size 1048576\"\n",
    "    },\n",
    "    {\n",
    "        \"template\": \"BLOCK* ask <*>:<*> to replicate <*> to datanode(s) <*>:<*>\",\n",
    "        \"message\": \"BLOCK* ask 127.0.0.1:50010 to replicate blk_1073741836 to datanode(s) 127.0.0.1:50012\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File GA_calculator.py trong UNLEASH\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(df_groundtruth, df_parsedlog, filter_templates=None):\n",
    "    \"\"\" Đánh giá độ chính xác của việc phân tích log bằng cách so sánh dữ liệu ground truth và kết quả phân tích log. Phương thức này thực hiện các bước sau:\n",
    "        1. Loại bỏ các dòng không hợp lệ trong dữ liệu ground truth (các dòng có giá trị NaN trong cột `EventTemplate`).\n",
    "        2. Gọi hàm `get_accuracy` để tính toán các chỉ số độ chính xác:\n",
    "            - GA (Grouping Accuracy): Độ chính xác nhóm.\n",
    "            - FGA (F-Measure of Grouping Accuracy): Trung bình điều hòa giữa độ chính xác và độ bao phủ.\n",
    "        3. In kết quả GA và FGA ra màn hình.\n",
    "        4. Trả về giá trị GA và FGA.\n",
    "\n",
    "    Args:\n",
    "        df_groundtruth (pd.DataFrame): DataFrame chứa dữ liệu ground truth với cột `EventTemplate`.\n",
    "        df_parsedlog (pd.DataFrame): DataFrame chứa kết quả phân tích log với cột `EventTemplate`.\n",
    "        filter_templates (list, optional): Danh sách các template cần lọc. Nếu không được cung cấp, tất cả các template sẽ được sử dụng.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (GA, FGA), trong đó:\n",
    "            - GA (float): Độ chính xác nhóm (Grouping Accuracy).\n",
    "            - FGA (float): F-Measure của độ chính xác nhóm.\n",
    "    \"\"\" \n",
    "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index       # Lấy các chỉ số (index) không null từ df_groundtruth \n",
    "    df_groundtruth = df_groundtruth.loc[null_logids]                                    # Lọc df_groundtruth để chỉ giữ lại các dòng không null \n",
    "    df_parsedlog = df_parsedlog.loc[null_logids]                                        # Tương tự\n",
    "    GA, FGA = get_accuracy(df_groundtruth['EventTemplate'], df_parsedlog['EventTemplate'])\n",
    "    print('Grouping_Accuracy (GA): %.4f, FGA: %.4f,'%(GA, FGA))\n",
    "    return GA, FGA\n",
    "\n",
    "def get_accuracy(series_groundtruth, series_parsedlog, filter_templates=None):\n",
    "    \"\"\" Tính toán các chỉ số đánh giá độ chính xác giữa kết quả phân tích log và ground truth. Phương thức này tính toán hai chỉ số chính, gồm GA, FGA.\n",
    "\n",
    "    Args:\n",
    "        series_groundtruth (pandas.Series): Chuỗi chứa các template ground truth.\n",
    "        series_parsedlog (pandas.Series): Chuỗi chứa các template từ kết quả phân tích log.\n",
    "        filter_templates (list, optional): Danh sách các template cần lọc. Nếu không được cung cấp, tất cả các template sẽ được sử dụng để đánh giá độ chính xác. Nó được sử dụng để lọc các templates cụ thể trong quá trình tính toán độ chính xác. Nó cho phép người dùng chỉ tập trung vào một tập hợp con các template thay vì toàn bộ dữ liệu.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (GA, FGA), trong đó:\n",
    "            - GA (float): Độ chính xác nhóm (Grouping Accuracy).\n",
    "            - FGA (float): F-Measure của độ chính xác nhóm.\n",
    "\n",
    "    Example:\n",
    "        >>> series_groundtruth = pd.Series(['A', 'B', 'A', 'C'])\n",
    "        >>> series_parsedlog = pd.Series(['A', 'B', 'A', 'D'])\n",
    "        >>> get_accuracy(series_groundtruth, series_parsedlog)\n",
    "        (0.75, 0.6667)\n",
    "    \"\"\"\n",
    "    \n",
    "    series_groundtruth_valuecounts = series_groundtruth.value_counts()      # dtype: int64, A:3, B:2, C:1\n",
    "    series_parsedlog_valuecounts = series_parsedlog.value_counts()          # Tương tự\n",
    "    df_combined = pd.concat([series_groundtruth, series_parsedlog], axis=1, keys=['groundtruth', 'parsedlog'])\n",
    "    grouped_df = df_combined.groupby('groundtruth')                         # Kết hợp và nhóm dữ liệu theo cột 'groundtruth'\n",
    "    accurate_events = 0                                                     # Số lượng sự kiện chính xác          \n",
    "    accurate_templates = 0                                                  # Số lượng template chính xác\n",
    "    if filter_templates is not None:\n",
    "        filter_identify_templates = set()                                   # Tập hợp lưu trữ các template đã được xác định\n",
    "    \n",
    "    for ground_truthId, group in tqdm(grouped_df):\n",
    "        series_parsedlog_logId_valuecounts = group['parsedlog'].value_counts()          # Lấy số lượng các template phân tích được bởi công cụ cùng một nhóm với một template trong ground_truth \n",
    "        if filter_templates is not None and ground_truthId in filter_templates:         # Nếu template này đã có trong filter_templates và filter_templates không phải là None\n",
    "            for parsed_eventId in series_parsedlog_logId_valuecounts.index:             # ==> parsed_eventId = \"A\" hoặc \"B\"\n",
    "                filter_identify_templates.add(parsed_eventId)\n",
    "        if series_parsedlog_logId_valuecounts.size == 1:\n",
    "            parsed_eventId = series_parsedlog_logId_valuecounts.index[0]\n",
    "            if len(group) == series_parsedlog[series_parsedlog == parsed_eventId].size: # Nếu có một template duy nhất trong nhóm và số lượng dòng trong nhóm bằng với số lượng dòng trong series_parsedlog ==> Nhóm log đúng\n",
    "                if (filter_templates is None) or (ground_truthId in filter_templates):\n",
    "                    accurate_events += len(group)\n",
    "                    accurate_templates += 1\n",
    "    if filter_templates is not None:\n",
    "        GA = float(accurate_events) / len(series_groundtruth[series_groundtruth.isin(filter_templates)])        # Tính toán dựa trên số lượng trong filter_templates (phương thức isin() trả về True nếu giá trị trong series nằm trong filter_templates)\n",
    "        PGA = float(accurate_templates) / len(filter_identify_templates)\n",
    "        RGA = float(accurate_templates) / len(filter_templates)\n",
    "    else:\n",
    "        GA = float(accurate_events) / len(series_groundtruth)\n",
    "        PGA = float(accurate_templates) / len(series_parsedlog_valuecounts)\n",
    "        RGA = float(accurate_templates) / len(series_groundtruth_valuecounts)\n",
    "    # print(FGA, RGA)\n",
    "    FGA = 0.0\n",
    "    if PGA != 0 or RGA != 0:\n",
    "        FGA = 2 * (PGA * RGA) / (PGA + RGA)\n",
    "    return GA, FGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File PA_calculator.py trong UNLEASH\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "\n",
    "def post_process_tokens(tokens, punc):\n",
    "    \"\"\" Phương thức thực hiện hậu xử lý danh sách các token cho trước, loại bỏ các ký tự không cần thiết và chuẩn hóa các token.\n",
    "    Chức năng chính:\n",
    "        1. Nếu một token chứa chuỗi \"<*>\", toàn bộ token sẽ được thay thế bằng \"<*>\".\n",
    "        2. Với các token khác, loại bỏ các ký tự không thuộc danh sách `punc`, không phải khoảng trắng (' '), \n",
    "           hoặc không nằm trong danh sách ký tự đặc biệt `excluded_str` (gồm '=', '|', '(', ')').\n",
    "           \n",
    "    Args:\n",
    "        tokens (list): Danh sách các token cần xử lý.\n",
    "        punc (str): Chuỗi chứa các ký tự phân cách và ký tự không cần thiết.    \n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các token đã được xử lý.\n",
    "        \n",
    "    Examples:\n",
    "        >>> tokens = [\"hello\", \"world<*>\", \"test|case\", \"a(b)c\"]\n",
    "        >>> punc = \"!\\\"#$%&'()+,-/:;=?@[\\\\]^_`{|}~\"\n",
    "        >>> post_process_tokens(tokens, punc)\n",
    "        ['hello', '<*>', 'test|case', 'abc']\n",
    "    \"\"\"\n",
    "    excluded_str = ['=', '|', '(', ')']                         # Các ký tự đặc biệt cần giữ lại\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i].find(\"<*>\") != -1:\n",
    "            tokens[i] = \"<*>\"\n",
    "        else:\n",
    "            new_str = \"\"\n",
    "            for s in tokens[i]:\n",
    "                if (s not in punc and s != ' ') or s in excluded_str:\n",
    "                    new_str += s\n",
    "            tokens[i] = new_str\n",
    "    return tokens\n",
    "\n",
    "def message_split(message):\n",
    "    \"\"\" Tách chuỗi đầu vào thành các token dựa trên các ký tự phân cách và thực hiện xử lý hậu kỳ. \n",
    "    Chức năng chính:\n",
    "        1. Tách chuỗi dựa trên các ký tự phân cách (khoảng trắng, dấu câu, ...).\n",
    "        2. Loại bỏ các token rỗng hoặc không hợp lệ.\n",
    "        3. Chuẩn hóa các token bằng cách loại bỏ các ký tự không cần thiết.\n",
    "        4. Loại bỏ các token `<*>` liên tiếp.\n",
    "\n",
    "    Args:\n",
    "        message (str): Chuỗi đầu vào cần tách.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách các token đã được xử lý.\n",
    "\n",
    "    Examples:\n",
    "        >>> message = \"Hello, world! This is a test <*> <*>.\"\n",
    "        >>> message_split(message)\n",
    "        ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '<*>', '.']\n",
    "    \"\"\"\n",
    "    \n",
    "    punc = \"!\\\"#$%&'()+,-/:;=?@.[\\]^_`{|}~\"                     # Các ký tự được sử dụng để phân tách\n",
    "    splitters = \"\\s\\\\\" + \"\\\\\".join(punc)                        # Tạo biểu thức chính quy để tách chuỗi\n",
    "    splitter_regex = re.compile(\"([{}]+)\".format(splitters))    \n",
    "    \n",
    "    # Ex: message = \"Hello, world! This is a test <*> <*>.\"\n",
    "    tokens = re.split(splitter_regex, message)          # tokens = ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '<*>', '<*>', '.']\n",
    "    tokens = list(filter(lambda x: x != \"\", tokens))    # tokens = ['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '<*>', '<*>', '.']\n",
    "    \n",
    "    tokens = post_process_tokens(tokens, punc)          # tokens = ['Hello', 'world', 'This', 'is', 'a', 'test', '<*>', '<*>']\n",
    "    tokens = [ \n",
    "        token.strip() \n",
    "        for token in tokens \n",
    "        if token != \"\" and token != ' ' \n",
    "    ] # Loại bỏ các token rỗng hoặc khoảng trắng\n",
    "    tokens = [ \n",
    "        token \n",
    "        for idx, token in enumerate(tokens) \n",
    "        if not (token == \"<*>\" and idx > 0 and tokens[idx - 1] == \"<*>\")\n",
    "    ] # Loại bỏ các token `<*>` liên tiếp\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def calculate_similarity(template1, template2):\n",
    "    \"\"\" Phương thức đo lường mức độ giống nhau giữa hai chuỗi văn bản (template1 và template2) bằng cách sử dụng Chỉ số Jaccard.\n",
    "    Chỉ số Jaccard là tỷ lệ giữa số lượng phần tử chung của hai tập hợp và tổng số phần tử của cả hai tập hợp.\n",
    "    \n",
    "    Args:\n",
    "        template1 (str): Chuỗi văn bản đầu tiên.\n",
    "        template2 (str): Chuỗi văn bản thứ hai. \n",
    "        \n",
    "    Returns:\n",
    "        float: Chỉ số Jaccard giữa hai chuỗi văn bản.    \n",
    "    \"\"\"\n",
    "    template1 = message_split(template1)\n",
    "    template2 = message_split(template2)\n",
    "    intersection = len(set(template1).intersection(set(template2)))             # Giao giữa hai template\n",
    "    union = (len(template1) + len(template2)) - intersection                    # Hợp giữa hai template\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def calculate_parsing_accuracy(groundtruth_df, parsedresult_df, filter_templates=None):\n",
    "    \"\"\" Tính toán độ chính xác của quá trình phân tích cú pháp (Parsing Accuracy - PA). \n",
    "    Quy trình hoạt động:\n",
    "        1. Nếu `filter_templates` được cung cấp, lọc dữ liệu thực tế và kết quả phân tích để chỉ giữ lại các template trong danh sách này.\n",
    "        2. So sánh cột `EventTemplate` giữa hai DataFrame để đếm số lượng message được phân tích đúng.\n",
    "        3. Tính toán độ chính xác phân tích cú pháp (PA) bằng cách chia số lượng message đúng cho tổng số message.\n",
    "        4. In ra độ chính xác phân tích cú pháp với định dạng 4 chữ số thập phân.\n",
    "    \n",
    "    Args:\n",
    "        groundtruth_df (pd.DataFrame): DataFrame chứa dữ liệu thực tế với cột `EventTemplate` và `Content`.\n",
    "        parsedresult_df (pd.DataFrame): DataFrame chứa kết quả phân tích với cột `EventTemplate` và `Content`.\n",
    "        filter_templates (list, optional): Danh sách các template cần sử dụng để tính toán.\n",
    "\n",
    "    Returns:\n",
    "        float: Độ chính xác của quá trình phân tích cú pháp (Parsing Accuracy - PA), được tính bằng tỷ lệ giữa số lượng message được phân tích đúng và tổng số message.\n",
    "\n",
    "    Examples:\n",
    "        >>> groundtruth_df = pd.DataFrame({\n",
    "        ...     'EventTemplate': ['A', 'B', 'C'],\n",
    "        ...     'Content': ['msg1', 'msg2', 'msg3']\n",
    "        ... })\n",
    "        >>> parsedresult_df = pd.DataFrame({\n",
    "        ...     'EventTemplate': ['A', 'B', 'D'],\n",
    "        ...     'Content': ['msg1', 'msg2', 'msg3']\n",
    "        ... })\n",
    "        >>> calculate_parsing_accuracy(groundtruth_df, parsedresult_df)\n",
    "        Parsing_Accuracy (PA): 0.6667\n",
    "        0.6667\n",
    "    \"\"\"\n",
    "    if filter_templates is not None:            # Nếu có filter_templates, tính toán theo các template chỉ định\n",
    "        groundtruth_df = groundtruth_df[groundtruth_df['EventTemplate'].isin(filter_templates)]\n",
    "        parsedresult_df = parsedresult_df.loc[groundtruth_df.index]\n",
    "        \n",
    "    correctly_parsed_messages = parsedresult_df[['EventTemplate']].eq(groundtruth_df[['EventTemplate']]).values.sum()\n",
    "    total_messages = len(parsedresult_df[['Content']])\n",
    "\n",
    "    PA = float(correctly_parsed_messages) / total_messages\n",
    "\n",
    "    print('Parsing_Accuracy (PA): {:.4f}'.format(PA))\n",
    "    return PA\n",
    "\n",
    "# Phương thức mới, tính toán độ tương đồng phân tích cú pháp:\n",
    "def calculate_similarity_accuracy(groundtruth_df, parsedresult_df, filter_templates=None):\n",
    "    \"\"\" Tính toán độ chính xác tương đồng giữa các template phân tích cú pháp và dữ liệu thực tế. Dùng được cho tất cả các trình phân tích cú pháp.\n",
    "    \n",
    "    Args:\n",
    "        groundtruth_df (pd.DataFrame): DataFrame chứa dữ liệu thực tế với cột `EventTemplate` và `Content`.\n",
    "        parsedresult_df (pd.DataFrame): DataFrame chứa kết quả phân tích với cột `EventTemplate` và `Content`.\n",
    "        filter_templates (list, optional): Danh sách các template cần sử dụng để tính toán.\n",
    "\n",
    "    Returns:\n",
    "        float: Độ chính xác tương đồng giữa các template phân tích cú pháp và dữ liệu thực tế.\n",
    "\n",
    "    Examples:\n",
    "        >>> groundtruth_df = pd.DataFrame({\n",
    "        ...     'EventTemplate': ['A', 'B', 'C'],\n",
    "        ...     'Content': ['msg1', 'msg2', 'msg3']\n",
    "        ... })\n",
    "        >>> parsedresult_df = pd.DataFrame({\n",
    "        ...     'EventTemplate': ['A', 'B', 'D'],\n",
    "        ...     'Content': ['msg1', 'msg2', 'msg3']\n",
    "        ... })\n",
    "        >>> calculate_similarity_accuracy(groundtruth_df, parsedresult_df)\n",
    "        Similarity_Accuracy (SA): 0.6667\n",
    "        0.6667\n",
    "    \"\"\"\n",
    "    if filter_templates is not None:\n",
    "        groundtruth_df = groundtruth_df[groundtruth_df['EventTemplate'].isin(filter_templates)]\n",
    "        parsedresult_df = parsedresult_df.loc[groundtruth_df.index]\n",
    "\n",
    "    similarities = []\n",
    "    for index in range(len(groundtruth_df)):\n",
    "        similarities.append(calculate_similarity(groundtruth_df['EventTemplate'][index], parsedresult_df['EventTemplate'][index]))\n",
    "    SA = sum(similarities) / len(similarities)\n",
    "    print('Similarity_Accuracy (SA): {:.4f}'.format(SA))\n",
    "    return SA\n",
    "\n",
    "def calculate_parsing_accuracy_lstm(groundtruth_df, parsedresult_df, filter_templates=None):\n",
    "    \"\"\" Tương tự, Tính toán độ chính xác của quá trình phân tích cú pháp (Parsing Accuracy - PA) cho các trình phân tích dựa trên ngữ nghĩa.\n",
    "        \n",
    "        Args:\n",
    "            groundtruth_df (pd.DataFrame): DataFrame chứa dữ liệu thực tế với cột `EventTemplate` và `Content`.\n",
    "            parsedresult_df (pd.DataFrame): DataFrame chứa kết quả phân tích với cột `EventTemplate` và `Content`.\n",
    "            filter_templates (list, optional): Danh sách các template cần sử dụng để tính toán.\n",
    "\n",
    "        Returns:\n",
    "            float: Độ chính xác của quá trình phân tích cú pháp (Parsing Accuracy - PA), được tính bằng tỷ lệ giữa số lượng message được phân tích đúng và tổng số message.\n",
    "        \"\"\"\n",
    "    if filter_templates is not None:\n",
    "        groundtruth_df = groundtruth_df[groundtruth_df['EventTemplate'].isin(filter_templates)]\n",
    "        parsedresult_df = parsedresult_df.loc[groundtruth_df.index]\n",
    "\n",
    "    # Tương tự, nhưng thêm một phương thức tính toán (correct_lstm) để kiểm tra độ chính xác dành riêng cho các trình phân tích dựa trên ngữ nghĩa\n",
    "    groundtruth_templates = list(groundtruth_df['EventTemplate'])\n",
    "    parsedresult_templates = list(parsedresult_df['EventTemplate'])\n",
    "    correctly_parsed_messages = 0\n",
    "    for i in range(len(groundtruth_templates)):\n",
    "        if correct_lstm(groundtruth_templates[i], parsedresult_templates[i]):\n",
    "            correctly_parsed_messages += 1\n",
    "\n",
    "    PA = float(correctly_parsed_messages) / len(groundtruth_templates)\n",
    "    print('Parsing_Accuracy (PA): {:.4f}'.format(PA))\n",
    "    return PA\n",
    "\n",
    "def correct_lstm(groudtruth, parsedresult):\n",
    "    \"\"\" Phương thức tính toán độ chính xác phân tích dành riêng cho các trình phân tích cú pháp dựa trên ngữ nghĩa. Bản chất, chỉ chỉnh sửa lại, lọc các nhiễu trong groudtruth để so sánh với parsedresult.\n",
    "\n",
    "    Args:\n",
    "        groudtruth (str): Chuỗi văn bản gốc (ground truth).\n",
    "        parsedresult (str): Chuỗi văn bản đã được phân tích (parsed result).\n",
    "\n",
    "    Returns:\n",
    "        bool: Trả về True nếu hai danh sách từ giống nhau, ngược lại trả về False.\n",
    "    \"\"\"\n",
    "    tokens1 = groudtruth.split(' ')\n",
    "    tokens2 = parsedresult.split(' ')\n",
    "    tokens1 = [\n",
    "        \"<*>\" \n",
    "        if \"<*>\" in token else token \n",
    "        for token in tokens1\n",
    "    ]       # Chỉnh sửa lại token trong groudtruth\n",
    "    return tokens1 == tokens2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File common.py trong UNLEASH\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import regex as re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from natsort import natsorted\n",
    "\n",
    "\n",
    "all_datasets = [\n",
    "    \"Proxifier\",\n",
    "    \"Linux\",\n",
    "    \"Apache\",\n",
    "    \"Zookeeper\",\n",
    "    \"Mac\",\n",
    "    \"OpenStack\",\n",
    "    \"HealthApp\",\n",
    "    \"Hadoop\",\n",
    "    \"HPC\",\n",
    "    \"OpenSSH\",\n",
    "    \"BGL\",\n",
    "    \"HDFS\",\n",
    "    # \"Android\",\n",
    "    \"Spark\",\n",
    "    # \"Windows\",\n",
    "    \"Thunderbird\",\n",
    "]\n",
    "\n",
    "datasets = ['HDFS', 'Hadoop', 'Spark', 'Zookeeper', 'OpenStack', 'BGL', 'HPC', 'Thunderbird', 'Windows', 'Linux', 'Mac', 'Android', 'HealthApp', 'Apache', 'OpenSSH', 'Proxifier']  \n",
    "\n",
    "\n",
    "def sort_templates(templates):\n",
    "    \"\"\" Sắp xếp danh sách các template theo độ dài giảm dần.\n",
    "    Args:\n",
    "        templates (list): Danh sách các template cần sắp xếp.\n",
    "    Returns:\n",
    "        list: Danh sách các template đã được sắp xếp theo thứ tự giảm dần của độ dài.\n",
    "    \"\"\"\n",
    "    return sorted(templates, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "\n",
    "def get_pattern_from_template(template):\n",
    "    \"\"\" Tạo một biểu thức chính quy (regular expression) từ một template. Template có thể chứa các ký tự đặc biệt và ký tự đại diện `<*>`. \n",
    "    Hàm này sẽ:\n",
    "    - Thoát (Escape) các ký tự đặc biệt trong template để đảm bảo chúng không bị hiểu nhầm.\n",
    "    - Thay thế các khoảng trắng bằng biểu thức chính quy `\\s+` để khớp với một hoặc nhiều khoảng trắng.\n",
    "    - Thay thế ký tự đại diện `<*>` bằng `(\\S+?)` để khớp với một hoặc nhiều ký tự không phải khoảng trắng.    \n",
    "    - Thêm dấu `^` và `$` để biểu thức chính quy khớp toàn bộ chuỗi.\n",
    "\n",
    "    Args:\n",
    "        template (str): template cần chuyển đổi thành biểu thức chính quy.\n",
    "\n",
    "    Returns:\n",
    "        str: Biểu thức chính quy được tạo từ template.\n",
    "    \n",
    "    Examples:\n",
    "        >>> get_pattern_from_template(\"Error <*> occurred at <*>\")\n",
    "        '^Error\\\\s+(\\\\S+?)\\\\s+occurred\\\\s+at\\\\s+(\\\\S+?)$'\n",
    "\n",
    "        >>> get_pattern_from_template(\"File <*> not found\")\n",
    "        '^File\\\\s+(\\\\S+?)\\\\s+not\\\\s+found$'\n",
    "\n",
    "        >>> get_pattern_from_template(\"User <*> logged in at <*>\")\n",
    "        '^User\\\\s+(\\\\S+?)\\\\s+logged\\\\s+in\\\\s+at\\\\s+(\\\\S+?)$'\n",
    "    \"\"\"\n",
    "    escaped = re.escape(template)\n",
    "    spaced_escape = re.sub(r'\\\\\\s+', \"\\\\\\s+\", escaped)\n",
    "    return \"^\" + spaced_escape.replace(r\"<\\*>\", r\"(\\S+?)\") + \"$\"  # Một <*> duy nhất có thể sử dụng nhiều token\n",
    "\n",
    "def is_abstract(x, y):\n",
    "    \"\"\" Xác định xem template `x` có trừu tượng hơn chuỗi `y` hay không. Hàm này kiểm tra xem chuỗi `y` có khớp với biểu thức chính quy được tạo từ template `x` hay không. Template `x` có thể chứa ký tự đại diện `<*>`, đại diện cho một hoặc nhiều ký tự không phải khoảng trắng.\n",
    "\n",
    "    Args:\n",
    "        x (str): template (template).\n",
    "        y (str): Chuỗi cần kiểm tra (template hoặc message).\n",
    "\n",
    "    Returns:\n",
    "        bool: Trả về `True` nếu `x` trừu tượng hơn `y`, ngược lại trả về `False`.\n",
    "\n",
    "    Ví dụ:\n",
    "        x = \"Hello <*>\"\n",
    "        y = \"Hello world\"\n",
    "        is_abstract(x, y)  # Trả về True\n",
    "\n",
    "        y = \"Hi world\"\n",
    "        is_abstract(x, y)  # Trả về False\n",
    "    \"\"\"\n",
    "\n",
    "    if y is np.nan:\n",
    "        return False\n",
    "\n",
    "    m = re.match(get_pattern_from_template(x), y)\n",
    "    if m:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def common_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-otc', '--oracle_template_correction',\n",
    "                        help=\"Set this if you want to use corrected oracle templates\",\n",
    "                        default=False, action='store_true')\n",
    "    parser.add_argument('-full', '--full_data',\n",
    "                        help=\"Set this if you want to test on full dataset\",\n",
    "                        default=False, action='store_true')\n",
    "    parser.add_argument('--complex', type=int,\n",
    "                        help=\"Set this if you want to test on complex dataset\",\n",
    "                        default=0)\n",
    "    parser.add_argument('--frequent', type=int,\n",
    "                        help=\"Set this if you want to test on frequent dataset\",\n",
    "                        default=0)\n",
    "    parser.add_argument('--shot', type=int,\n",
    "                        help=\"Set this if you want to test on complex dataset\",\n",
    "                        default=0)\n",
    "    parser.add_argument('--example_size', type=int,\n",
    "                        help=\"Set this if you want to test on frequent dataset\",\n",
    "                        default=0)    \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def unique_output_dir(name):\n",
    "    \"\"\" Tạo một đường dẫn thư mục đầu ra duy nhất dựa trên tên cơ sở, thời gian hiện tại và ID tiến trình.\n",
    "\n",
    "    Args:\n",
    "        name (str): Tên cơ sở của thư mục.\n",
    "\n",
    "    Returns:\n",
    "        str: Đường dẫn thư mục đầu ra duy nhất.\n",
    "\n",
    "    Examples:\n",
    "        >>> unique_output_dir(\"experiment\")\n",
    "        'experiment_result/20231005_153045_12345'\n",
    "    \"\"\"\n",
    "    return os.path.join('{}_result'.format(name), '{}_{}'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"), os.getpid()))\n",
    "\n",
    "\n",
    "def correct_single_template(template, user_strings=None):\n",
    "    \"\"\" Áp dụng các quy tắc để xử lý và chuẩn hóa một chuỗi template. Dựa trên bài báo: \"Guidelines for Assessing the Accuracy of Log Message Template Identification Techniques (2023)\".\n",
    "    DOI: 10.1145/3510003.3510101\n",
    "\n",
    "    Các quy tắc được áp dụng:\n",
    "        - **DS (Double Space)**: Loại bỏ khoảng trắng thừa và chuẩn hóa chuỗi thành một khoảng trắng duy nhất. `Input:  <*>` --> `Input: <*>`\n",
    "        - **BL (Boolean)**: Thay thế các giá trị boolean như \"true\", \"false\" bằng ký tự đại diện `<*>`. `cancel=false` --> `cancel=<*>`\n",
    "        - **US (User String)**: Thay thế các chuỗi do người dùng định nghĩa (ex, \"null\", \"root\", \"admin\") bằng `<*>`. `status=idle` --> `status=<*>`\n",
    "        - **DG (Digit)**: Thay thế các giá trị số bằng `<*>`. `euid=0` --> `euid=<*>`\n",
    "        - **PS (Path String)**: Thay thế các chuỗi dạng đường dẫn bằng `<*>`. `/lib/tmp started` --> `<*> started`\n",
    "        - **WV (Word concatenated with Variable, hay Mixed Token (MT))**: Thay thế các chuỗi chứa `<*>` được nối với các ký tự khác. `python v<*>` --> `python <*>`\n",
    "        - **DV (Dot-separated Variables)**: Thay thế các chuỗi dạng `<*>.<*>` bằng `<*>`. `<*>.<*> seconds` --> `<*> seconds`\n",
    "        - **CV (Consecutive Variables)**: Thay thế các chuỗi `<*><*>` liên tiếp bằng `<*>`.  `value=<*><*>` --> `value=<*>`\n",
    "\n",
    "    Args:\n",
    "        template (str): Chuỗi template cần xử lý.\n",
    "        user_strings (set, optional): Tập hợp các chuỗi do người dùng định nghĩa cần thay thế bằng `<*>`.\n",
    "\n",
    "    Returns:\n",
    "        str: Chuỗi template đã được xử lý và chuẩn hóa.\n",
    "\n",
    "    Ví dụ:\n",
    "        >>> template = \"Received block <*> of size <*> from <*>\"\n",
    "        >>> correct_single_template(template)\n",
    "        'Received block <*> of size <*> from <*>'\n",
    "\n",
    "        >>> template = \"/path/to/file file/path\"\n",
    "        >>> correct_single_template(template)\n",
    "        '<*> file/path'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    boolean = {'true', 'false'}                 # Các giá trị boolean (BL)\n",
    "    default_strings = {'null', 'root', 'admin'} # Các chuỗi do người dùng định nghĩa, mặc định là 3 gtrị này (US)\n",
    "    path_delimiters = {                         # Các ký tự sử dụng phân tách đường dẫn (PS)\n",
    "        r'\\s', r'\\,', r'\\!', r'\\;', r'\\:',\n",
    "        r'\\=', r'\\|', r'\\\"', r'\\'',\n",
    "        r'\\[', r'\\]', r'\\(', r'\\)', r'\\{', r'\\}'\n",
    "    }\n",
    "    token_delimiters = path_delimiters.union({  # Sử dụng để phân tách các kỹ thuật rule còn lại (DG, WV, DV, CV)\n",
    "        r'\\.', r'\\-', r'\\+', r'\\@', r'\\#', r'\\$', r'\\%', r'\\&',\n",
    "    })\n",
    "\n",
    "    if user_strings:\n",
    "        default_strings = default_strings.union(user_strings) # Nếu có các chuỗi do người dùng định nghĩa, thêm vào danh sách mặc định\n",
    "\n",
    "    # Áp dụng DS (Double Space)\n",
    "    template = template.strip()\n",
    "    template = re.sub(r'\\s+', ' ', template)\n",
    "\n",
    "    # Áp dụng PS (Path String)\n",
    "    p_tokens = re.split('('+'|'.join(path_delimiters)+')', template)\n",
    "    new_p_tokens = []\n",
    "    for p_token in p_tokens:\n",
    "        if re.match(r'^(\\/[^\\/]+)+$', p_token):\n",
    "            p_token = '<*>'\n",
    "        new_p_tokens.append(p_token)\n",
    "    template = ''.join(new_p_tokens)\n",
    "\n",
    "    # Phân tách thành các token để xủ lý các rule con lại \n",
    "    tokens = re.split('('+'|'.join(token_delimiters)+')', template)  # Chuẩn hóa token nhưng vẫn giữ lại các ký tự phân tách\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        # Áp dụng BL (Boolean), US (User String)\n",
    "        for to_replace in boolean.union(default_strings):\n",
    "            if token.lower() == to_replace.lower():                 # ==> Chuyển thành chữ thường để so sánh\n",
    "                token = '<*>'\n",
    "\n",
    "        # Áp dụng DG (Digit)\n",
    "        if re.match(r'^\\d+$', token):\n",
    "            token = '<*>'\n",
    "\n",
    "        # Áp dụng WV (Word concatenated with Variable), hay Mixed Token (MT)\n",
    "        if re.match(r'^[^\\s\\/]*<\\*>[^\\s\\/]*$', token):\n",
    "            if token != '<*>/<*>':  # Cần kiểm tra vì `/` không phải là ký tự phân tách\n",
    "                token = '<*>'\n",
    "\n",
    "        # Thu thập các token đã xử lý\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    # Tạo ra template mới, template hoàn chỉnh với độ trừu tượng cao\n",
    "    template = ''.join(new_tokens)\n",
    "\n",
    "    # Chỉ thay thế các biến liên tiếp nếu được phân tách bằng bất kỳ phân tách nào bao gồm \".\" (DV)\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*>\\.<\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "\n",
    "    # Chỉ thay thế các biến liên tiếp nếu không được phân tách bằng bất kỳ phân tách nào bao gồm khoảng trắng (CV)\n",
    "    # NOTE: Quá trình này nên thực hiện cuối cùng để tránh thay thế các biến liên tiếp không cần thiết\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*><\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "\n",
    "    return template\n",
    "\n",
    "\n",
    "def correct_templates_and_update_files(dir_path, log_file_basename, inplace=False):\n",
    "    \"\"\" Cập nhật file log có cấu trúc và file template sau khi sửa các template theo luật hậu xử lý.\n",
    "    - Nếu một template bị thay đổi nội dung (nhưng không thay đổi EventId), chỉ cập nhật cột `EventTemplate`.\n",
    "    - Nếu nhiều template được gộp thành một (ví dụ do khái quát hóa), cập nhật cả `EventId` và `EventTemplate` trong structured log. EventId mới được chọn là EventId đầu tiên trong nhóm ban đầu để giữ đồng nhất.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): Đường dẫn tới thư mục chứa các file structured log và template.\n",
    "        log_file_basename (str): Tên gốc của file log (ví dụ: `BGL_2k.log`). Hàm sẽ dùng để tìm các file liên quan như\n",
    "                                 `BGL_2k.log_structured.csv`.\n",
    "        inplace (bool, optional): Nếu True, các file structured log và templates sẽ được ghi đè;\n",
    "                                  nếu False, sẽ tạo ra các file mới với hậu tố `_corrected.csv`.\n",
    "\n",
    "    Returns:\n",
    "        None: Hàm không trả về giá trị, \n",
    "\n",
    "    Examples:\n",
    "        >>> File input:\n",
    "            templates:\n",
    "                E1, Send 123\n",
    "                E2, Send 456\n",
    "\n",
    "        >>> structured log:\n",
    "                LineId, Content, EventId, EventTemplate\n",
    "                1, Send 123, E1, Send 123\n",
    "                2, Send 456, E2, Send 456\n",
    "\n",
    "        Sau khi gộp và xử lý:\n",
    "        >>> templates:\n",
    "                E1, Send <*>\n",
    "        Và:\n",
    "        >>> structured log:\n",
    "                1, Send 123, E1, Send <*>\n",
    "                2, Send 456, E1, Send <*>\n",
    "        Ví dụ:\n",
    "        >>> correct_templates_and_update_files(\"./logs/\", \"BGL_2k.log\", inplace=False)\n",
    "    \"\"\"\n",
    "\n",
    "    # Tạo đường dẫn đến file structured log\n",
    "    org_structured_log_file = os.path.join(dir_path, log_file_basename + '_structured.csv')\n",
    "\n",
    "    # Chuyển dữ liệu từ file structured log thành DataFrame\n",
    "    structured_logs_df = pd.read_csv(org_structured_log_file)\n",
    "\n",
    "    # Trích xuất template qua biến templates_df\n",
    "    # Loại bỏ các dòng trùng lặp dựa trên cột EventTemplate. Sau đó, loại bỏ các dòng có giá trị NaN trong cột EventTemplate, sử dụng dropna (điều này cần thiết vì một số công cụ như LogSig có thể tạo ra các template rỗng).\n",
    "    templates_df = structured_logs_df.drop_duplicates(subset='EventTemplate').dropna(subset=['EventTemplate'])\n",
    "\n",
    "    # Chuyển templates_df thành dictionary (key: EventId, value: EventTemplate)\n",
    "    templates_dict = templates_df.set_index('EventId')['EventTemplate'].to_dict()\n",
    "\n",
    "    # Áp dụng 8 quy tắc sửa template và gộp template\n",
    "    new_templates_dict = correct_templates(templates_dict)\n",
    "\n",
    "    # Cập nhật DataFrame structured_logs_df\n",
    "    start_time = time.time()\n",
    "    # Duyệt qua từng dòng trong structured_logs_df. Tìm template tương ứng với EventId trong new_templates_dict.\n",
    "    for index, row in structured_logs_df.iterrows():\n",
    "\n",
    "        is_matched = False\n",
    "        for tids, template in new_templates_dict.items():\n",
    "            if row['EventId'] in tids:  # Nếu tìm thấy, cập nhật EventId và EventTemplate trong DataFrame.\n",
    "                structured_logs_df.at[index, 'EventId'] = tids[0]\n",
    "                structured_logs_df.at[index, 'EventTemplate'] = template\n",
    "                is_matched = True\n",
    "                break\n",
    "\n",
    "        # Nếu không tìm thấy, in cảnh báo với thông tin EventId và nội dung (Content) của dòng đó.\n",
    "        if is_matched is False:\n",
    "            print('*** WARN: No matching template; EventId:', row['EventId'], 'message:', row['Content'])\n",
    "\n",
    "    # Cập nhật file structured log\n",
    "    if inplace:  # Ghi đè file gốc\n",
    "        structured_logs_df.to_csv(org_structured_log_file, index=False)\n",
    "    else:  # Sử dụng tên file mới với hậu tố _corrected.csv\n",
    "        structured_logs_df.to_csv(os.path.join(dir_path, log_file_basename + '_structured_corrected.csv'), index=False)\n",
    "\n",
    "    # Cập nhật file templates\n",
    "    new_templates = []\n",
    "    for tids, template in new_templates_dict.items():\n",
    "        new_templates.append((tids[0], template))\n",
    "    new_templates = natsorted(new_templates, key=lambda x: x[0])\n",
    "    new_templates_df = pd.DataFrame(new_templates, columns=['EventId', 'EventTemplate'])\n",
    "    new_templates_df.to_csv(os.path.join(dir_path, log_file_basename + '_templates_corrected.csv'), index=False)\n",
    "\n",
    "    print('Structured log and templates file update done. [Time taken: {:.3f}]'.format(time.time() - start_time))\n",
    "\n",
    "def correct_templates(templates_dict):\n",
    "    \"\"\"\n",
    "    Core function for template postprocessing.\n",
    "\n",
    "    :param templates_dict: existing templates (key: EventId, value: EventTemplate)\n",
    "    :return: new templates_dict (key: Tuple of EventIds, value: EventTemplate)\n",
    "    \"\"\"\n",
    "\n",
    "    # templates that are affected by the post-processing\n",
    "    change_count = 0\n",
    "    inverse_templates_dict = {}  # key: EventTemplate, value: list of EventIds\n",
    "\n",
    "    start_time = time.time()\n",
    "    for tid, template in sorted(templates_dict.items(), key=lambda x: x[0]):  # sort to avoid non-determinism\n",
    "        org_template = template\n",
    "        new_template = correct_single_template(template)\n",
    "\n",
    "        # count the number of changed templates\n",
    "        if org_template != new_template:\n",
    "            change_count += 1\n",
    "\n",
    "        # update temp_templates_dict\n",
    "        if new_template in inverse_templates_dict.keys():\n",
    "            inverse_templates_dict[new_template].append(tid)\n",
    "        else:\n",
    "            inverse_templates_dict[new_template] = [tid]\n",
    "\n",
    "    # build new_templates_dict using inverse_templates_dict\n",
    "    new_templates_dict = {tuple(tids): template for template, tids in inverse_templates_dict.items()}\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "    print('\\tOriginal templates:', len(templates_dict.keys()))\n",
    "    print('\\tTemplates after correction:', len(new_templates_dict.keys()))\n",
    "    print(\"\\tTemplates changed by correction:\", change_count)\n",
    "    print('Template correction done. [Time taken: {:.3f}]'.format(end_time))\n",
    "\n",
    "    return new_templates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File template_level_analysis.py trong UNLEASH\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "# from unleash.evaluation.utils.common import is_abstract\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_template_level(dataset, df_groundtruth, df_parsedresult, filter_templates=None):\n",
    "    \"\"\"\n",
    "    Đánh giá mức độ chính xác của template ở mức template-level dựa trên các kết quả phân tích đã cho, bao gồm các chỉ số FTA, PTA, RTA. Cách thực hiện tương tự như tính chỉ số GA, FGA\n",
    "\n",
    "    Args:\n",
    "        dataset: Tập dữ liệu đầu vào (không được sử dụng trong hàm này).\n",
    "        df_groundtruth (pd.DataFrame): DataFrame chứa các template sự kiện thực tế (groundtruth), với cột 'EventTemplate'.\n",
    "        df_parsedresult (pd.DataFrame): DataFrame chứa các template sự kiện được phân tích (parsed result), với cột 'EventTemplate'.\n",
    "        filter_templates (set, optional): Tập hợp các template cần lọc để đánh giá. Nếu không được cung cấp, sẽ đánh giá toàn bộ.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Gồm các giá trị:\n",
    "            - t1 (int): Số lượng template được nhận diện.\n",
    "            - t2 (int): Số lượng template thực tế.\n",
    "            - FTA (float): Giá trị F1-Score (F-Measure) của việc phân tích template.\n",
    "            - PTA (float): Độ chính xác (Precision Template Accuracy).\n",
    "            - RTA (float): Độ bao phủ (Recall Template Accuracy).\n",
    "\n",
    "    Examples:\n",
    "        >>> dataset = None\n",
    "        >>> df_groundtruth = pd.DataFrame({'EventTemplate': ['A', 'B', 'C', None]})\n",
    "        >>> df_parsedresult = pd.DataFrame({'EventTemplate': ['A', 'B', 'D', None]})\n",
    "        >>> filter_templates = {'A', 'B'}\n",
    "        >>> evaluate_template_level(dataset, df_groundtruth, df_parsedresult, filter_templates)\n",
    "        Identify : 2, Groundtruth : 2\n",
    "        PTA: 1.0000, RTA: 1.0000 FTA: 1.0000\n",
    "        (2, 2, 1.0, 1.0, 1.0)\n",
    "    \"\"\"\n",
    "    # Tương tự như quy trình tính toán chỉ số GA, nhưng có một số điểm khác nhau.\n",
    "    correct_parsing_templates = 0               # Số lượng template được phân tích đúng\n",
    "    if filter_templates is not None:\n",
    "        filter_identify_templates = set()\n",
    "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index\n",
    "    df_groundtruth = df_groundtruth.loc[null_logids]\n",
    "    df_parsedresult = df_parsedresult.loc[null_logids]\n",
    "    series_groundtruth = df_groundtruth['EventTemplate']\n",
    "    series_parsedlog = df_parsedresult['EventTemplate']\n",
    "    series_groundtruth_valuecounts = series_groundtruth.value_counts()\n",
    "\n",
    "    df_combined = pd.concat([series_groundtruth, series_parsedlog], axis=1, keys=['groundtruth', 'parsedlog'])\n",
    "    grouped_df = df_combined.groupby('parsedlog')   # Tính toán theo template của parserlog\n",
    "    \n",
    "    for identified_template, group in tqdm(grouped_df):\n",
    "        corr_oracle_templates = set(list(group['groundtruth'])) # DS các template thực tế tương ứng với template phân tích\n",
    "\n",
    "        if filter_templates is not None and len(corr_oracle_templates.intersection(set(filter_templates))) > 0:\n",
    "            filter_identify_templates.add(identified_template)\n",
    "\n",
    "        if corr_oracle_templates == {identified_template}:\n",
    "            if (filter_templates is None) or (identified_template in filter_templates):\n",
    "                correct_parsing_templates += 1\n",
    "\n",
    "    if filter_templates is not None:\n",
    "        PTA = correct_parsing_templates / len(filter_identify_templates)\n",
    "        RTA = correct_parsing_templates / len(filter_templates)\n",
    "    else:\n",
    "        PTA = correct_parsing_templates / len(grouped_df)\n",
    "        RTA = correct_parsing_templates / len(series_groundtruth_valuecounts)\n",
    "    FTA = 0.0\n",
    "    if PTA != 0 or RTA != 0:\n",
    "        FTA = 2 * (PTA * RTA) / (PTA + RTA)\n",
    "    print('PTA: {:.4f}, RTA: {:.4f} FTA: {:.4f}'.format(PTA, RTA, FTA))\n",
    "    t1 = len(grouped_df) if filter_templates is None else len(filter_identify_templates)\n",
    "    t2 = len(series_groundtruth_valuecounts) if filter_templates is None else len(filter_templates)\n",
    "    print(\"Identify : {}, Groundtruth : {}\".format(t1, t2))\n",
    "    return t1, t2, FTA, PTA, RTA\n",
    "\n",
    "\n",
    "def evaluate_template_level_lstm(dataset, df_groundtruth, df_parsedresult, filter_templates=None):\n",
    "    \"\"\" Tương tự, tính toán chỉ số FTA, PTA, RTA cho các trình phân tích cú pháp dựa trên ngữ nghĩa. Quy trình hoạt động tương tự như evaluate_template_level, nhưng sử dụng một phương thức kiểm tra độ chính xác khác (correct_lstm).\n",
    "    Args:\n",
    "        dataset: Tập dữ liệu đầu vào (không được sử dụng trong hàm này).\n",
    "        df_groundtruth (pd.DataFrame): DataFrame chứa các template sự kiện thực tế (groundtruth), với cột 'EventTemplate'.\n",
    "        df_parsedresult (pd.DataFrame): DataFrame chứa các template sự kiện được phân tích (parsed result), với cột 'EventTemplate'.\n",
    "        filter_templates (set, optional): Tập hợp các template cần lọc để đánh giá. Nếu không được cung cấp, sẽ đánh giá toàn bộ.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Gồm các giá trị:\n",
    "            - t1 (int): Số lượng template được nhận diện.\n",
    "            - t2 (int): Số lượng template thực tế.\n",
    "            - FTA (float): Giá trị F1-Score (F-Measure) của việc phân tích template.\n",
    "            - PTA (float): Độ chính xác (Precision Template Accuracy).\n",
    "            - RTA (float): Độ bao phủ (Recall Template Accuracy).\n",
    "    \"\"\"\n",
    "\n",
    "    correct_parsing_templates = 0\n",
    "    if filter_templates is not None:\n",
    "        filter_identify_templates = set()\n",
    "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index\n",
    "    df_groundtruth = df_groundtruth.loc[null_logids]\n",
    "    df_parsedresult = df_parsedresult.loc[null_logids]\n",
    "    series_groundtruth = df_groundtruth['EventTemplate']\n",
    "    series_parsedlog = df_parsedresult['EventTemplate']\n",
    "    series_groundtruth_valuecounts = series_groundtruth.value_counts()\n",
    "\n",
    "    df_combined = pd.concat([series_groundtruth, series_parsedlog], axis=1, keys=['groundtruth', 'parsedlog'])\n",
    "    grouped_df = df_combined.groupby('parsedlog')\n",
    "    \n",
    "    for identified_template, group in tqdm(grouped_df):\n",
    "        corr_oracle_templates = set(list(group['groundtruth']))\n",
    "        if filter_templates is not None and len(corr_oracle_templates.intersection(set(filter_templates))) > 0:\n",
    "            filter_identify_templates.add(identified_template)\n",
    "        \n",
    "        if len(corr_oracle_templates) == 1 and correct_lstm(identified_template, list(corr_oracle_templates)[0]):\n",
    "            if (filter_templates is None) or (list(corr_oracle_templates)[0] in filter_templates):\n",
    "                correct_parsing_templates += 1\n",
    "\n",
    "    if filter_templates is not None:\n",
    "        PTA = correct_parsing_templates / len(filter_identify_templates)\n",
    "        RTA = correct_parsing_templates / len(filter_templates)\n",
    "    else:\n",
    "        PTA = correct_parsing_templates / len(grouped_df)\n",
    "        RTA = correct_parsing_templates / len(series_groundtruth_valuecounts)\n",
    "    FTA = 0.0\n",
    "    if PTA != 0 or RTA != 0:\n",
    "        FTA = 2 * (PTA * RTA) / (PTA + RTA)\n",
    "    print('PTA: {:.4f}, RTA: {:.4f} FTA: {:.4f}'.format(PTA, RTA, FTA))\n",
    "    t1 = len(grouped_df) if filter_templates is None else len(filter_identify_templates)\n",
    "    t2 = len(series_groundtruth_valuecounts) if filter_templates is None else len(filter_templates)\n",
    "    print(\"Identify : {}, Groundtruth : {}\".format(t1, t2))\n",
    "    return t1, t2, FTA, PTA, RTA\n",
    "\n",
    "\n",
    "def correct_lstm(groudtruth, parsedresult):\n",
    "    \"\"\" Phương thức sử dụng để tính toán độ chính xác phân tích dành riêng cho các trình phân tích cú pháp dựa trên ngữ nghĩa. Bản chất, chỉ chỉnh sửa lại, lọc các nhiễu trong groudtruth để so sánh với parsedresult. \n",
    "    \"\"\"\n",
    "    tokens1 = groudtruth.split(' ')\n",
    "    tokens2 = parsedresult.split(' ')\n",
    "    tokens1 = [\"<*>\" if \"<*>\" in token else token for token in tokens1]\n",
    "    return tokens1 == tokens2\n",
    "\n",
    "# def compute_template_level_accuracy(num_oracle_template, comparison_results_df):\n",
    "#     \"\"\"\n",
    "#     Tính toán độ chính xác ở cấp độ Template (template-level accuracy), dựa trên kết quả phân loại từng template thành các nhóm:\n",
    "\n",
    "#     - **SM (Strict Match)**: Template phát hiện khớp hoàn toàn với template groundtruth.\n",
    "#     - **OG (Over-Generalized)**: Template phát hiện quá khái quát, đại diện cho nhiều template groundtruth khác nhau.\n",
    "#     - **UG (Under-Generalized)**: Template phát hiện quá cụ thể, chia nhỏ một template groundtruth thành nhiều cái.\n",
    "#     - **MX (Mixed)**: Trường hợp template vừa bị OG vừa bị UG.\n",
    "\n",
    "#     Các chỉ số được tính:\n",
    "#     - **Precision (PTA)**: Tỷ lệ template phát hiện đúng (SM) / tổng số template được phát hiện.\n",
    "#     - **Recall (RTA)**: Tỷ lệ template phát hiện đúng (SM) / tổng số template groundtruth.\n",
    "#     - **F1-Score (FTA)**: Trung bình điều hòa giữa precision và recall.\n",
    "#     - **OG, UG, MX**: Tỷ lệ các lỗi phát hiện template (OG, UG, MX) so với tổng số template được phát hiện.\n",
    "\n",
    "#     Args:\n",
    "#         num_oracle_template (int): Tổng số template groundtruth (được gán nhãn đúng từ ban đầu).\n",
    "#         comparison_results_df (pandas.DataFrame): Bảng dữ liệu chứa các template được công cụ phát hiện. Phải có cột `type` thể hiện loại so khớp (`SM`, `OG`, `UG`, `MX`).\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Gồm các giá trị sau:\n",
    "#             - f1_measure (float): F1-score của việc phát hiện template.\n",
    "#             - precision (float): Precision (PTA).\n",
    "#             - recall (float): Recall (RTA).\n",
    "#             - over_generalized (float): Tỷ lệ OG templates.\n",
    "#             - under_generalized (float): Tỷ lệ UG templates.\n",
    "#             - mixed (float): Tỷ lệ MX templates.\n",
    "\n",
    "#     Examples:\n",
    "#         >>> import pandas as pd\n",
    "#         >>> data = {'EventTemplate': ['T1', 'T2', 'T3', 'T4', 'T5'],\n",
    "#         ...         'type': ['SM', 'OG', 'SM', 'UG', 'MX']}\n",
    "#         >>> df = pd.DataFrame(data)\n",
    "#         >>> compute_template_level_accuracy(5, df)\n",
    "#         (0.4, 0.4, 0.4, 0.2, 0.2, 0.2)\n",
    "#     \"\"\"\n",
    "#     count_total = float(len(comparison_results_df)) # Tổng số template được phát hiện\n",
    "#     over_generalized = len(comparison_results_df[comparison_results_df.type == 'OG']) / count_total     # Tỷ lệ OG templates\n",
    "#     under_generalized = len(comparison_results_df[comparison_results_df.type == 'UG']) / count_total     # Tỷ lệ UG templates\n",
    "#     mixed = len(comparison_results_df[comparison_results_df.type == 'MX']) / count_total\n",
    "#     return over_generalized, under_generalized, mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File evaluator_main.py trong UNLEASH\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "from multiprocessing import Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# from unleash.evaluation.utils.common import correct_templates_and_update_files\n",
    "# from unleash.evaluation.utils.GA_calculator import evaluate\n",
    "# from unleash.evaluation.utils.template_level_analysis import evaluate_template_level, evaluate_template_level_lstm\n",
    "# from unleash.evaluation.utils.PA_calculator import calculate_parsing_accuracy, calculate_parsing_accuracy_lstm\n",
    "# from .post_process import correct_single_template\n",
    "\n",
    "# TIMEOUT = 3600 * 12  # log template identification timeout (sec)\n",
    "TIMEOUT = 3600 * 48  # log template identification timeout (sec)\n",
    "\n",
    "\n",
    "def prepare_results(output_dir):\n",
    "    \"\"\" Phương thức chuẩn bị file kết quả trong thư mục đầu ra. Hàm này thực hiện các bước sau:\n",
    "    1. Kiểm tra xem thư mục đầu ra (`output_dir`) có tồn tại hay không. Nếu không, tạo thư mục mới.\n",
    "    2. Kiểm tra xem tệp kết quả `'parsing_accuracy.csv'` đã tồn tại trong thư mục hay chưa. Nếu chưa, tạo tệp mới và ghi dòng tiêu đề vào tệp CSV. Trả về tên tệp kết quả.\n",
    "\n",
    "    Args:\n",
    "        - output_dir (str): Đường dẫn đến thư mục đầu ra.\n",
    "\n",
    "    Returns:\n",
    "        - str: Tên tệp kết quả (`'parsing_accuracy.csv'`).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        # Tạo mới nếu không tồn tại\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Tạo tệp kết quả nếu chưa tồn tại\n",
    "    result_file = 'parsing_accuracy.csv'\n",
    "    if not os.path.exists(os.path.join(output_dir, result_file)):\n",
    "        with open(os.path.join(output_dir, result_file), 'w') as csv_file:\n",
    "            fw = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "            fw.writerow(['Dataset', 'traning_time', 'parsing_time', 'identified_templates',\n",
    "                        'ground_templates', 'GA', 'PA', 'FGA', 'PTA', 'RTA', 'FTA']) # Tiêu đề cột trong tệp CSV\n",
    "\n",
    "    return result_file\n",
    "\n",
    "\n",
    "def correct_template_general(template):\n",
    "    \"\"\" Phương thức thực hiện chỉnh sửa lỗi template chuẩn theo 2 quy tắc chính (DV, CV).\n",
    "    Args:\n",
    "        template (str): Chuỗi template cần xử lý.\n",
    "    Returns:\n",
    "        str: Chuỗi template đã được xử lý và chuẩn hóa.\n",
    "    \"\"\"\n",
    "    # Chỉ thay thế các biến liên tiếp nếu được phân tách bằng bất kỳ phân tách nào bao gồm \".\" (DV)\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*>\\.<\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "\n",
    "    # Thay thế các biến liên tiếp (CV)\n",
    "    # NOTE: Cần phải thực hiện cuối cùng\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*><\\*>', '<*>', template)\n",
    "        template = re.sub(r'<\\*>\\:<\\*>', '<*>', template)\n",
    "        template = re.sub(r'<\\*> <\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "        \n",
    "    return template\n",
    "\n",
    "def align_with_null_values(groudtruth_row):\n",
    "    \"\"\" Căn chỉnh các giá trị null trong template sự kiện với nội dung thực tế. Phương thức này giúp đảm bảo rằng các template được căn chỉnh chính xác với nội dung, đặc biệt trong các trường hợp có placeholder (<*>) hoặc các giá trị null.\n",
    "    Args:\n",
    "        groudtruth_row (dict): Một dictionary chứa:\n",
    "            - 'Content' (str): Chuỗi nội dung thực tế.\n",
    "            - 'EventTemplate' (str): Chuỗi template sự kiện.\n",
    "\n",
    "    Returns:\n",
    "        str: Chuỗi template sự kiện đã được căn chỉnh với nội dung thực tế.\n",
    "\n",
    "    Examples:\n",
    "        >>> groudtruth_row = {\n",
    "        ...     'Content': 'User logged in from 192.168.1.1',\n",
    "        ...     'EventTemplate': 'User <*> in from <*>'\n",
    "        ... }\n",
    "        >>> align_with_null_values(groudtruth_row)\n",
    "        'User <*> in from <*>'\n",
    "\n",
    "        >>> groudtruth_row = {\n",
    "        ...     'Content': 'File uploaded successfully',\n",
    "        ...     'EventTemplate': 'File <*> successfully'\n",
    "        ... }\n",
    "        >>> align_with_null_values(groudtruth_row)\n",
    "        'File <*> successfully'\n",
    "    \"\"\"\n",
    "\n",
    "    log = groudtruth_row['Content']\n",
    "    template = groudtruth_row['EventTemplate']\n",
    "\n",
    "    # Tạo biểu thức chính quy theo template để so khớp với log\n",
    "    pattern_parts = template.split(\"<*>\")\n",
    "    pattern_parts_escaped = [re.escape(part) for part in pattern_parts]\n",
    "    regex_pattern = \"(.*?)\".join(pattern_parts_escaped)\n",
    "    regex = \"^\" + regex_pattern + \"$\"  \n",
    "    matches = re.search(regex, log)\n",
    "\n",
    "    if matches == None:     # Nếu không khớp với chuỗi ban đầu, trả về template gốc\n",
    "        return template\n",
    "\n",
    "    parts = []\n",
    "    for index, part in enumerate(template.split(\"<*>\")):\n",
    "        parts.append(part)\n",
    "        if index < len(matches.groups()):\n",
    "            if matches.groups()[index] == '':\n",
    "                parts.append('')\n",
    "            else:\n",
    "                parts.append('<*>')\n",
    "    return ''.join(parts)\n",
    "\n",
    "\n",
    "def is_file_empty(file_path):\n",
    "    \"\"\" Phương thức kiểm tra xem tệp có rỗng hay không.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Đường dẫn đến tệp cần kiểm tra.\n",
    "\n",
    "    Returns:\n",
    "        bool: Trả về True nếu tệp rỗng, ngược lại trả về False.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        return len(content) == 0\n",
    "\n",
    "\n",
    "def evaluator(\n",
    "        dataset,\n",
    "        input_dir,\n",
    "        output_dir,\n",
    "        log_file,\n",
    "        result_file,\n",
    "        lstm=False\n",
    "):\n",
    "    \"\"\" Phương thức đánh giá hiệu suất phân tích log dựa trên file đầu ra đã phân tích và dữ liệu ground truth. Tuy nhiên, đây chỉ sử dụng cho UNLEASH, chưa tổng quát như Loghub 2.0. File này chưa có tùy chọn chỉnh sửa lại các lỗi trong template, tùy chọn đánh giá trên các tập template cụ thể, ...\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Tên của tập dữ liệu log.\n",
    "        input_dir (str): Thư mục chứa log gốc và ground truth.\n",
    "        output_dir (str): Thư mục chứa kết quả phân tích (parsed log).\n",
    "        log_file (str): Tên file log cần đánh giá (không bao gồm phần structured).\n",
    "        result_file (str): Tên file kết quả tổng hợp sẽ được ghi.\n",
    "        lstm (bool, optional): Nếu True, sử dụng phương pháp đánh giá có liên quan đến LSTM.\n",
    "\n",
    "    Returns:\n",
    "        None. Kết quả được ghi trực tiếp vào `result_file`.\n",
    "\n",
    "    Examples:\n",
    "        >>> evaluator(\n",
    "                dataset=\"HDFS\",\n",
    "                input_dir=\"logs/raw\",\n",
    "                output_dir=\"logs/parsed\",\n",
    "                log_file=\"HDFS.log\",\n",
    "                result_file=\"summary.csv\",\n",
    "                lstm=False\n",
    "            )\n",
    "    \"\"\"\n",
    "\n",
    "    print('\\n=== Evaluation on %s ===' % dataset)\n",
    "    # Xác định đường dẫn đến file log gốc và file ground truth\n",
    "    indir = os.path.join(input_dir, os.path.dirname(log_file))\n",
    "    log_file_basename = os.path.basename(log_file)\n",
    "    \n",
    "    groundtruth = os.path.join(indir, log_file_basename + '_structured.csv')\n",
    "    parsedresult = os.path.join(output_dir, log_file_basename + '_structured.csv')\n",
    "\n",
    "    # print(parsedresult)\n",
    "    if not os.path.exists(parsedresult) or is_file_empty(parsedresult): # Xử lý nếu không tồn tại\n",
    "        print(\"No output file generated.\")\n",
    "        result = dataset + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + '\\n'\n",
    "                # \"{:.1f}\".format(GA_end_time) + ',' + \\\n",
    "                # \"{:.1f}\".format(PA_end_time) + ',' + \\\n",
    "                # \"{:.1f}\".format(TA_end_time) + ',' + \\\n",
    "\n",
    "        with open(os.path.join(output_dir, result_file), 'a') as summary_file:\n",
    "            summary_file.write(result)\n",
    "        return   \n",
    "\n",
    "    parsedresult = pd.read_csv(parsedresult, dtype=str)\n",
    "    parsedresult.fillna(\"\", inplace=True)               # Thay thế giá trị NaN bằng chuỗi rỗng\n",
    "    groundtruth = pd.read_csv(groundtruth, dtype=str)\n",
    "\n",
    "    # Chuẩn hóa các template bằng phương thức `align_with_null_values` và `correct_template_general`\n",
    "    tqdm.pandas()\n",
    "    print(\"Start to align with null values\")\n",
    "    groundtruth['EventTemplate'] = groundtruth.progress_apply(align_with_null_values, axis=1)\n",
    "    groundtruth['EventTemplate'] = groundtruth['EventTemplate'].map(correct_template_general)\n",
    "    parsedresult['EventTemplate'] = parsedresult.progress_apply(align_with_null_values, axis=1)\n",
    "\n",
    "    filter_templates = None\n",
    "    print(\"Start compute grouping accuracy\")\n",
    "    # Tính toán chỉ số GA bằng phương thức `evaluate` trong GA_calculator.py\n",
    "    start_time = time.time()\n",
    "    GA, FGA = evaluate(groundtruth, parsedresult, filter_templates)\n",
    "\n",
    "    GA_end_time = time.time() - start_time\n",
    "    print('Grouping Accuracy calculation done. [Time taken: {:.3f}]'.format(GA_end_time))\n",
    "\n",
    "    # Tính toán chỉ số PA bằng phương thức `calculate_parsing_accuracy` trong PA_calculator.py\n",
    "    start_time = time.time()\n",
    "    if lstm == True:\n",
    "        PA = calculate_parsing_accuracy_lstm(groundtruth, parsedresult, filter_templates)\n",
    "        print(\"Finish calculate_parsing_accuracy_lstm\")\n",
    "    else:\n",
    "        PA = calculate_parsing_accuracy(groundtruth, parsedresult, filter_templates)\n",
    "    PA_end_time = time.time() - start_time\n",
    "    print('Parsing Accuracy calculation done. [Time taken: {:.3f}]'.format(PA_end_time))\n",
    "\n",
    "    # Tính toán chỉ số FTA, PTA, RTA bằng phương thức `evaluate_template_level` trong template_level_analysis.py\n",
    "    start_time = time.time()\n",
    "    if lstm == True:\n",
    "        tool_templates, ground_templates, FTA, PTA, RTA = evaluate_template_level_lstm(dataset, groundtruth, parsedresult, filter_templates)\n",
    "    else:\n",
    "        tool_templates, ground_templates, FTA, PTA, RTA = evaluate_template_level(dataset, groundtruth, parsedresult, filter_templates)\n",
    "    TA_end_time = time.time() - start_time\n",
    "    print('Template-level accuracy calculation done. [Time taken: {:.3f}]'.format(TA_end_time))\n",
    "\n",
    "    # Đọc thời gian phân tích và thời gian huấn luyện \n",
    "    time_cost_file = os.path.join(output_dir, 'time_cost.json')\n",
    "    parsing_time, training_time = 0, 0\n",
    "    if os.path.exists(time_cost_file):\n",
    "        with open(time_cost_file, 'r') as file:\n",
    "            time_table = json.load(file)\n",
    "            training_time = time_table[dataset]['TrainingTime']\n",
    "            parsing_time = time_table[dataset]['ParsingTime']\n",
    "\n",
    "    # Ghi kết quả vào result_file\n",
    "    result = dataset + ',' + \\\n",
    "             \"{:.3f}\".format(training_time) + ',' + \\\n",
    "             \"{:.3f}\".format(parsing_time) + ',' + \\\n",
    "             str(tool_templates) + ',' + \\\n",
    "             str(ground_templates) + ',' + \\\n",
    "             \"{:.3f}\".format(GA) + ',' + \\\n",
    "             \"{:.3f}\".format(PA) + ',' + \\\n",
    "             \"{:.3f}\".format(FGA) + ',' + \\\n",
    "             \"{:.3f}\".format(PTA) + ',' + \\\n",
    "             \"{:.3f}\".format(RTA) + ',' + \\\n",
    "             \"{:.3f}\".format(FTA) + '\\n'\n",
    "             # \"{:.1f}\".format(GA_end_time) + ',' + \\\n",
    "             # \"{:.1f}\".format(PA_end_time) + ',' + \\\n",
    "             # \"{:.1f}\".format(TA_end_time) + ',' + \\\n",
    "\n",
    "    with open(os.path.join(output_dir, result_file), 'a') as summary_file:\n",
    "        summary_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File oracle_template_correction.py trong UNLEASH\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "# from evaluation.utils.common import correct_templates_and_update_files, datasets\n",
    "\n",
    "def main():\n",
    "    # Thực hiện quy trình xử lý và cập nhật các file log có cấu trúc và file template cho từng loại dataset.\n",
    "    for system in datasets:\n",
    "        print('-' * 70)\n",
    "        print(system)\n",
    "        dir_path = os.path.join('..', 'logs', system)\n",
    "        log_file_basename = system + '_2k.log'\n",
    "        correct_templates_and_update_files(dir_path, log_file_basename, inplace=False) # Cập nhật lại và ghi ra file mới\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File post_process.py trong UNLEASH\n",
    "import regex as re\n",
    "\n",
    "param_regex = [\n",
    "    r'{([ :_#.\\-\\w\\d]+)}', # Tìm các chuỗi nằm trong cặp dấu ngoặc nhọn {}. Ex: text = \"This is a {template_1} and another {example:template#2}.\" --> re.findall(pattern, text) = ['template_1', 'example:template#2']\n",
    "    r'{}'                  # Tìm các cặp dấu ngoặc nhọn {} rỗng, không chứa bất kỳ nội dung nào bên trong. Ex: text = \"This is a {} and another {}.\" --> re.findall(pattern, text) = ['{}', '{}']\n",
    "] # Biến này không được sử dụng\n",
    "\n",
    "def correct_single_template(template, user_strings=None):\n",
    "    \"\"\" Áp dụng các quy tắc để xử lý và chuẩn hóa một chuỗi template. Phương thức này sử dụng thêm các trường hợp liên tiếp khác ngoài CV, DV để chỉnh sửa lỗi template một cách toàn diện hơn\n",
    "\n",
    "    Args:\n",
    "        template (str): Chuỗi template cần xử lý.\n",
    "        user_strings (set, optional): Tập hợp các chuỗi do người dùng định nghĩa cần thay thế bằng `<*>`.\n",
    "\n",
    "    Returns:\n",
    "        str: Chuỗi template đã được xử lý và chuẩn hóa.\n",
    "    \"\"\"\n",
    "\n",
    "    boolean = {}\n",
    "    default_strings = {}\n",
    "    path_delimiters = {                         # Dấu phân tách sử dụng cho đường dẫn (PS)\n",
    "        r'\\s', r'\\,', r'\\!', r'\\;', r'\\:',\n",
    "        r'\\=', r'\\|', r'\\\"', r'\\'',\n",
    "        r'\\[', r'\\]', r'\\(', r'\\)', r'\\{', r'\\}'\n",
    "    }\n",
    "    token_delimiters = path_delimiters.union({  # Các dấu phân tách sử dụng cho các trường hợp còn lại\n",
    "        r'\\.', r'\\-', r'\\+', r'\\@', r'\\#', r'\\$', r'\\%', r'\\&',\n",
    "    })\n",
    "\n",
    "    if user_strings:\n",
    "        default_strings = default_strings.union(user_strings)\n",
    "\n",
    "    # Áp dụng DS\n",
    "    template = template.strip()\n",
    "    template = re.sub(r'\\s+', ' ', template)\n",
    "\n",
    "    # Áp dụng PS, tuy nhiên trong phuơng thức này không sử dụng đến PS\n",
    "    # p_tokens = re.split('(' + '|'.join(path_delimiters) + ')', template)\n",
    "    # new_p_tokens = []\n",
    "    # for p_token in p_tokens:\n",
    "        # if re.match(r'^(\\/[^\\/]+)+$', p_token):\n",
    "            # p_token = '<*>'\n",
    "        # new_p_tokens.append(p_token)\n",
    "    # template = ''.join(new_p_tokens)\n",
    "\n",
    "    # Áp dụng các quy tắc còn lại\n",
    "    tokens = re.split('(' + '|'.join(token_delimiters) + ')', template)  # Chuẩn hóa token nhưng vẫn giữ lại dấu phân tách\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        # Áp dụng BL, US, trong phương thức này không áp dụng\n",
    "        # for to_replace in boolean.union(default_strings):\n",
    "            # if token.lower() == to_replace.lower():\n",
    "                # token = '<*>'\n",
    "\n",
    "        # Áp dụng DG\n",
    "        if re.match(r'^\\d+$', token):\n",
    "            token = '<*>'\n",
    "\n",
    "        # Áp dụng WV\n",
    "        if re.match(r'^[^\\s\\/]*<\\*>[^\\s\\/]*$', token):\n",
    "            if token != '<*>/<*>':  # need to check this because `/` is not a deliminator\n",
    "                token = '<*>'\n",
    "\n",
    "        # Thu thập kết quả\n",
    "        new_tokens.append(token)\n",
    "\n",
    "    # Tạo template mới từ các token đã xử lý\n",
    "    template = ''.join(new_tokens)\n",
    "\n",
    "    # Áp dụng DV\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*>\\.<\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "\n",
    "    # Áp dụng CV\n",
    "    # NOTE: Thực hiện cuối cùng\n",
    "    while True:\n",
    "        prev = template\n",
    "        template = re.sub(r'<\\*><\\*>', '<*>', template)\n",
    "        if prev == template:\n",
    "            break\n",
    "    \n",
    "    # Đây là các trường hợp khác ngoài CV, DV, biến thể của CV:\n",
    "    while \" #<*># \" in template:\n",
    "        template = template.replace(\" #<*># \", \" <*> \")\n",
    "\n",
    "    while \" #<*> \" in template:\n",
    "        template = template.replace(\" #<*> \", \" <*> \")\n",
    "\n",
    "    while \"<*>:<*>\" in template:\n",
    "        template = template.replace(\"<*>:<*>\", \"<*>\")\n",
    "\n",
    "    while \"<*>#<*>\" in template:\n",
    "        template = template.replace(\"<*>#<*>\", \"<*>\")\n",
    "\n",
    "    while \"<*>/<*>\" in template:\n",
    "        template = template.replace(\"<*>/<*>\", \"<*>\")\n",
    "\n",
    "    while \"<*>@<*>\" in template:\n",
    "        template = template.replace(\"<*>@<*>\", \"<*>\")\n",
    "\n",
    "    while \"<*>.<*>\" in template:\n",
    "        template = template.replace(\"<*>.<*>\", \"<*>\")\n",
    "\n",
    "    # while \"<*>,<*>\" in template:\n",
    "    #     template = template.replace(\"<*>,<*>\", \"<*>\")\n",
    "\n",
    "    while ' \"<*>\" ' in template:\n",
    "        template = template.replace(' \"<*>\" ', ' <*> ')\n",
    "\n",
    "    while \" '<*>' \" in template:\n",
    "        template = template.replace(\" '<*>' \", \" <*> \")\n",
    "\n",
    "    while \"<*><*>\" in template:\n",
    "        template = template.replace(\"<*><*>\", \"<*>\")\n",
    "\n",
    "    # while \"[<*>]\" in template:\n",
    "    #     template = template.replace(\"[<*>]\", \"<*>\")\n",
    "\n",
    "    # while \"(<*>)\" in template:\n",
    "    #     template = template.replace(\"(<*>)\", \"<*>\")\n",
    "\n",
    "    # while \"{<*>}\" in template:\n",
    "    #     template = template.replace(\"{<*>}\", \"<*>\")    \n",
    "\n",
    "    # while \"<*> <*>\" in template:\n",
    "    #     template = template.replace(\"<*> <*>\", \"<*>\")\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File postprocess.py trong UNLEASH\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def post_average(metric_file):\n",
    "    \"\"\" Thêm dòng trung bình vào file chỉ số đánh giá, sau đó chuyển vị bảng.\n",
    "\n",
    "    Args:\n",
    "        metric_file (str): Đường dẫn đến file CSV chứa các chỉ số đánh giá (metrics).\n",
    "                           File cần có cột 'Dataset' và các cột số để tính trung bình.\n",
    "\n",
    "    Returns:\n",
    "        None. Hàm này sẽ ghi đè file gốc với bảng đã được cập nhật.\n",
    "    Examples:\n",
    "        Với file `metrics.csv` như sau:\n",
    "\n",
    "        >>> Dataset,Accuracy,Precision,Recall\n",
    "        ... HDFS,0.85,0.87,0.83\n",
    "        ... BGL,0.88,0.89,0.86\n",
    "        ... HDFS,0.85,0.87,0.83  # dòng trùng sẽ bị loại bỏ\n",
    "\n",
    "        Sau khi chạy `post_average(\"metrics.csv\")`, file sẽ thành:\n",
    "        >>> Dataset,HDFS,BGL,Average\n",
    "        ... Accuracy,0.85,0.88,0.865\n",
    "        ... Precision,0.87,0.89,0.88\n",
    "        ... Recall,0.83,0.86,0.845\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metric_file, index_col=False)\n",
    "    df = df.drop_duplicates(['Dataset'])                            # Xóa các dòng trùng lặp dựa trên cột 'Dataset'\n",
    "    mean_row = df.select_dtypes(include=[np.number]).mean().round(3)# Tính toán giá trị trung bình, làm tròn 3 chữ số\n",
    "    new_row = pd.DataFrame([['Average']], columns=['Dataset']).join(pd.DataFrame([mean_row.values], columns=mean_row.index))                # Tạo một DataFrame mới với giá trị trung bình\n",
    "    df = pd.concat([df, new_row], ignore_index=True)                # Thêm dòng \"Average\" vào cuối bảng.\n",
    "    df.to_csv(metric_file, index=False)                             # Ghi đè bảng đã cập nhật vào file gốc.\n",
    "    \n",
    "    # Mở lại file và chuyển vị (transpose) bảng (dòng ↔ cột), sau đó lưu lại.\n",
    "    df = pd.read_csv(metric_file)\n",
    "    transposed_df = df.transpose()\n",
    "    transposed_df.to_csv(metric_file)                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Đến các file trong Loghub 2.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File postprocess.py trong Loghub 2.0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def post_average(metric_file, tech, complex, frequent):\n",
    "    \"\"\" Tính trung bình các chỉ số đánh giá từ file CSV, thêm dòng 'Average', lưu vào file kết quả theo đường dẫn được xác định dựa vào tham số, và chuyển vị bảng kết quả. Phương thức này mở rộng hơn và toàn diện hơn.\n",
    "\n",
    "    Args:\n",
    "        metric_file (str): Đường dẫn file CSV chứa metric (có cột 'Dataset').\n",
    "        tech (str): Tên kỹ thuật/thuật toán (vd: 'Drain', 'IPLoM',...).\n",
    "        complex (int): Cờ cho biết có đang xử lý dữ liệu log phức tạp không.\n",
    "                       (≠ 0 → ghi vào thư mục 'complex/')\n",
    "        frequent (int): Cờ cho biết có đang xử lý lọc theo tần suất không.\n",
    "                        (≠ 0 → ghi vào thư mục 'frequent/')\n",
    "\n",
    "    Returns:\n",
    "        - File kết quả CSV lưu tại:\n",
    "            '../../result/{tech}.csv' (mặc định)\n",
    "            '../../result/complex/{tech}.csv' nếu `complex` ≠ 0\n",
    "            '../../result/frequent/{tech}.csv' nếu `frequent` ≠ 0\n",
    "        - Bảng kết quả được chuyển vị để dễ quan sát (dataset → cột).\n",
    "\n",
    "    Examples:\n",
    "        Giả sử file `Drain.csv` trong `metrics/` có nội dung:\n",
    "        >>> Dataset,Accuracy,Precision\n",
    "        ... HDFS,0.85,0.87\n",
    "        ... BGL,0.88,0.89\n",
    "        \n",
    "        Sau khi chạy:\n",
    "        >>> post_average(\"metrics/Drain.csv\", \"Drain\", 0, 0)\n",
    "\n",
    "        → File `../../result/Drain.csv` sẽ thành:\n",
    "        >>> ,0,1,2\n",
    "        ... Dataset,HDFS,BGL,Average\n",
    "        ... Accuracy,0.85,0.88,0.865\n",
    "        ... Precision,0.87,0.89,0.88\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(metric_file, index_col=False)\n",
    "    df = df.drop_duplicates(['Dataset'])                # Loại bỏ các dòng trùng nhau theo tên Dataset.\n",
    "    \n",
    "    # Tính trung bình các cột kiểu số (float/int), làm tròn 3 chữ số, để chính xác hơn\n",
    "    mean_row = df.select_dtypes(include=[np.number]).mean().round(3)\n",
    "    new_row = pd.DataFrame([['Average']], columns=['Dataset']).join(pd.DataFrame([mean_row.values], columns=mean_row.index))                                            # Tạo một DataFrame mới chứa giá trị trung bình.\n",
    "    df = pd.concat([df, new_row], ignore_index=True)   # Thêm dòng 'Average' vào cuối bảng.\n",
    "    \n",
    "    # Gán đường dẫn lưu kết quả:\n",
    "    output_path = f\"../../result/{tech}.csv\"\n",
    "    if complex != 0:\n",
    "        output_path = f\"../../result/complex/{tech}.csv\"\n",
    "    if frequent != 0:\n",
    "        output_path = f\"../../result/frequent/{tech}.csv\"\n",
    "    df.to_csv(output_path, index=False)                # Ghi bảng kết quả vào file CSV mới.\n",
    "    \n",
    "    # Mở lại file, chuyển vị (transpose), rồi lưu lại lần nữa: Dòng trở thành cột (và ngược lại).\n",
    "    df = pd.read_csv(output_path)\n",
    "    transposed_df = df.transpose()\n",
    "    transposed_df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File evaluator_main.py trong Loghub 2.0\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import chardet\n",
    "from multiprocessing import Process\n",
    "# from logparser.utils.evaluator import evaluate\n",
    "# from evaluation.utils.template_level_analysis import evaluate_template_level, evaluate_template_level_lstm\n",
    "# from evaluation.utils.PA_calculator import calculate_parsing_accuracy, calculate_parsing_accuracy_lstm\n",
    "import pandas as pd\n",
    "\n",
    "# TIMEOUT = 3600 * 12  # log template identification timeout (sec)\n",
    "TIMEOUT = 3600 * 12  # log template identification timeout (sec)\n",
    "\n",
    "\n",
    "def prepare_results(output_dir, otc, complex, frequent):\n",
    "    \"\"\" Chuẩn bị tệp CSV để lưu trữ kết quả phân tích. Phương thức này kiểm tra và tạo thư mục đầu ra nếu chưa tồn tại, sau đó tạo một tệp CSV với tiêu đề (header) được xác định trước.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Đường dẫn đến thư mục đầu ra nơi tệp CSV sẽ được lưu.\n",
    "        otc (bool): Giá trị boolean để chỉ định một thuộc tính cụ thể (ví dụ: có bật OTC hay không).\n",
    "        complex (bool): Giá trị boolean để chỉ định tính phức tạp.\n",
    "        frequent (bool): Giá trị boolean để chỉ định tần suất.\n",
    "\n",
    "    Returns:\n",
    "        str: Tên tệp CSV đã được tạo.\n",
    "\n",
    "    Examples:\n",
    "        >>> prepare_results(\"output\", True, False, True)\n",
    "        'summary_[otc=True,complex=0,frequent=1].csv'\n",
    "\n",
    "        >>> prepare_results(\"results\", False, True, False)\n",
    "        'summary_[otc=False,complex=1,frequent=0].csv'\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    result_file = 'summary_[otc={},complex={},frequent={}].csv'.format(str(otc), str(int(complex)), str(int(frequent)))\n",
    "    with open(os.path.join(output_dir, result_file), 'w') as csv_file:\n",
    "        fw = csv.writer(csv_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        # fw.writerow(['Dataset', 'GA_time', 'PA_time', 'TA_time', 'parse_time', 'identified_templates',\n",
    "        #              'ground_templates', 'GA', 'PA', 'FTA', 'PTA', 'RTA', 'OG', 'UG', 'MX'])\n",
    "        fw.writerow(['Dataset', 'parse_time', 'identified_templates',\n",
    "                     'ground_templates', 'GA', 'PA', 'FGA', 'PTA', 'RTA', 'FTA'])\n",
    "\n",
    "    return result_file\n",
    "\n",
    "\n",
    "def is_file_empty(file_path):\n",
    "    \"\"\" Phương thức kiểm tra xem tệp có rỗng hay không.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Đường dẫn đến tệp cần kiểm tra.\n",
    "\n",
    "    Returns:\n",
    "        bool: Trả về True nếu tệp rỗng, ngược lại trả về False.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        return len(content) == 0\n",
    "\n",
    "\n",
    "def evaluator(\n",
    "        dataset,\n",
    "        input_dir,\n",
    "        output_dir,\n",
    "        log_file,\n",
    "        LogParser,\n",
    "        param_dict,\n",
    "        otc,\n",
    "        complex,\n",
    "        frequent,\n",
    "        result_file,\n",
    "        lstm=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Hàm đánh giá hiệu suất phân tích log dựa trên các chỉ số: GA, PA, FTA, RTA, PTA. Đây là hàm đánh giá chung nhất, tổng quát nhất, có thể sử dụng để đánh giá cho các trình phân tích log khác nhau.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Tên tập dữ liệu log (ví dụ: HDFS, BGL).\n",
    "        input_dir (str): Thư mục chứa log và ground truth.\n",
    "        output_dir (str): Thư mục chứa kết quả phân tích.\n",
    "        log_file (str): Tên file log gốc.\n",
    "        LogParser (class): Class parser (ví dụ Drain) sẽ được khởi tạo để thực thi phân tích log.\n",
    "        param_dict (dict): Từ điển tham số khởi tạo cho parser.\n",
    "        otc (bool): Nếu True, sử dụng ground truth có sửa template theo oracle.\n",
    "        complex (int): Chế độ lọc mẫu phức tạp (0: không lọc, 1: đơn giản, 2: vừa, 3: phức tạp).\n",
    "        frequent (int): Chế độ lọc mẫu theo tần suất (0: không lọc, >0: ít phổ biến, <0: phổ biến).\n",
    "        result_file (str): Tên file CSV chứa kết quả đánh giá.\n",
    "        lstm (bool, optional): Nếu True, dùng phương pháp đánh giá template có liên quan đến LSTM.\n",
    "\n",
    "    Returns:\n",
    "        None. Kết quả đánh giá được ghi vào file `result_file` trong thư mục output.\n",
    "\n",
    "    Examples:\n",
    "        >>> evaluator(\n",
    "                dataset='HDFS',\n",
    "                input_dir='logs/raw',\n",
    "                output_dir='logs/parsed',\n",
    "                log_file='HDFS.log',\n",
    "                LogParser=Drain,\n",
    "                param_dict={\"log_format\": \"<Date> <Time> <Pid> <Level> <Component>: <Content>\"},\n",
    "                otc=True,\n",
    "                complex=2,\n",
    "                frequent=10,\n",
    "                result_file='summary.csv',\n",
    "                lstm=False\n",
    "            )\n",
    "    \"\"\"\n",
    "    print('\\n=== Evaluation on %s ===' % dataset)\n",
    "    indir = os.path.join(input_dir, os.path.dirname(log_file))\n",
    "    log_file_basename = os.path.basename(log_file)\n",
    "    \n",
    "    # Nếu có otc, sử dụng tệp log đã được chỉnh sửa\n",
    "    if otc:\n",
    "        # Sử dụng tệp log đã được chỉnh sửa (corrected oracle templates)\n",
    "        groundtruth = os.path.join(indir, log_file_basename + '_structured_corrected.csv')\n",
    "    else:\n",
    "        groundtruth = os.path.join(indir, log_file_basename + '_structured.csv')\n",
    "\n",
    "    parsedresult = os.path.join(output_dir, log_file_basename + '_structured.csv')\n",
    "    \n",
    "    # Xác định template bằng cách sử dụng các trình phân tích (ex, Drain)\n",
    "    start_time = time.time()\n",
    "    if LogParser != None:\n",
    "        print(\"start parsing.\")\n",
    "        parser = LogParser(**param_dict)\n",
    "        p = Process(target=parser.parse, args=(log_file_basename,)) # Tạo tiến trình riêng biệt để thực hiện phân tích\n",
    "        p.start()\n",
    "        p.join(timeout=TIMEOUT)     # Nếu tiến trình hoàn thành trong thời gian cho phép, tiếp tục. Nếu không, tiếp tục dòng sau kiểm tra p.is_alive()\n",
    "        if p.is_alive():            # Nếu parser chạy quá lâu thì huỷ\n",
    "            print('*** TIMEOUT for Template Identification')\n",
    "            p.terminate()\n",
    "            with open(parsedresult, 'w') as fw:\n",
    "                pass                # Không ghi kết quả\n",
    "            return\n",
    "        print(\"end parsing.\")\n",
    "        parse_time = time.time() - start_time  # end_time là thời gian trên đồng hồ tính bằng giây\n",
    "    else:\n",
    "        parse_time = -1\n",
    "    print(\"parsing time: \", parse_time)\n",
    "\n",
    "    # Nếu không có tệp kết quả phân tích hoặc tệp rỗng, ghi lại kết quả vào tệp CSV và thoát\n",
    "    if not os.path.exists(parsedresult) or is_file_empty(parsedresult):\n",
    "        print(\"No output file generated.\")\n",
    "        result = dataset + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + ',' + \\\n",
    "                \"None\" + '\\n'\n",
    "                # \"{:.1f}\".format(GA_end_time) + ',' + \\\n",
    "                # \"{:.1f}\".format(PA_end_time) + ',' + \\\n",
    "                # \"{:.1f}\".format(TA_end_time) + ',' + \\\n",
    "\n",
    "        with open(os.path.join(output_dir, result_file), 'a') as summary_file:\n",
    "            summary_file.write(result)\n",
    "        return   \n",
    "\n",
    "\n",
    "    filter_templates = None\n",
    "    # Lọc theo độ phức tạp (complexity) của template theo bài báo \"Loghub 2.0\"\n",
    "    if complex != 0:\n",
    "        print(\"Evaluate on complex mode: \", complex)\n",
    "        template_file = os.path.join(indir, log_file_basename + '_templates.csv')\n",
    "        df = pd.read_csv(template_file)\n",
    "        if complex == 1:\n",
    "            df = df[df['EventTemplate'].str.count('<*>') == 0]\n",
    "        if complex == 2:\n",
    "            df = df[(df['EventTemplate'].str.count('<*>') >= 1) & (df['EventTemplate'].str.count('<*>') <= 4)]\n",
    "        if complex == 3:\n",
    "            df = df[df['EventTemplate'].str.count('<*>') >= 5]\n",
    "        filter_templates = df['EventTemplate'].tolist()\n",
    "    \n",
    "    # Lọc theo tần suất (frequency) của template theo bài báo \"Loghub 2.0\"\n",
    "    if frequent != 0:\n",
    "        print(\"Evaluate on frequent mode: \", frequent)\n",
    "        template_file = os.path.join(indir, log_file_basename + '_templates.csv')\n",
    "        df = pd.read_csv(template_file)\n",
    "        df_sorted = df.sort_values('Occurrences')                  # Các template ít xuất hiện → nằm ở đầu danh sách.\n",
    "        if frequent > 0:\n",
    "            n = int(len(df_sorted) / 100.0 * frequent)\n",
    "            filter_templates = df_sorted['EventTemplate'].tolist()[:n] # lấy n template đầu tiên (ít xuất hiện nhất).\n",
    "        else:\n",
    "            n = len(df_sorted) - int(len(df_sorted) / 100.0 * -frequent)\n",
    "            filter_templates = df_sorted['EventTemplate'].tolist()[n:] # lấy n template cuối cùng (xuất hiện nhiều nhất).\n",
    "\n",
    "    if filter_templates != None:\n",
    "        print(\"length of filter templates: \", len(filter_templates))\n",
    "\n",
    "    # Dừng nếu không có mẫu nào sau khi lọc\n",
    "    if filter_templates != None and len(filter_templates) == 0: \n",
    "        return   \n",
    "\n",
    "    parsedresult = pd.read_csv(parsedresult, dtype=str)\n",
    "    parsedresult.fillna(\"\", inplace=True)\n",
    "    groundtruth = pd.read_csv(groundtruth, dtype=str)\n",
    "\n",
    "\n",
    "    print(\"Start compute grouping accuracy\")\n",
    "    # Tính toán chỉ số GA bằng phương thức `evaluate` trong GA_calculator.py\n",
    "    start_time = time.time()\n",
    "    GA, FGA = evaluate(groundtruth, parsedresult, filter_templates)\n",
    "\n",
    "    GA_end_time = time.time() - start_time\n",
    "    print('Grouping Accuracy calculation done. [Time taken: {:.3f}]'.format(GA_end_time))\n",
    "\n",
    "    # Tính toán chỉ số PA bằng phương thức `calculate_parsing_accuracy` trong PA_calculator.py\n",
    "    start_time = time.time()\n",
    "    if lstm == True:\n",
    "        PA = calculate_parsing_accuracy_lstm(groundtruth, parsedresult, filter_templates)\n",
    "        print(\"Finish calculate_parsing_accuracy_lstm\")\n",
    "    else:\n",
    "        PA = calculate_parsing_accuracy(groundtruth, parsedresult, filter_templates)\n",
    "    PA_end_time = time.time() - start_time\n",
    "    print('Parsing Accuracy calculation done. [Time taken: {:.3f}]'.format(PA_end_time))\n",
    "\n",
    "    # Tính toán chỉ số FTA, PTA, RTA bằng phương thức `evaluate_template_level` trong template_level_analysis.py\n",
    "    start_time = time.time()\n",
    "    if lstm == True:\n",
    "        tool_templates, ground_templates, FTA, PTA, RTA = evaluate_template_level_lstm(dataset, groundtruth, parsedresult, filter_templates)\n",
    "    else:\n",
    "        tool_templates, ground_templates, FTA, PTA, RTA = evaluate_template_level(dataset, groundtruth, parsedresult, filter_templates)\n",
    "    TA_end_time = time.time() - start_time\n",
    "    print('Template-level accuracy calculation done. [Time taken: {:.3f}]'.format(TA_end_time))\n",
    "\n",
    "    result = dataset + ',' + \\\n",
    "             \"{:.2f}\".format(parse_time) + ',' + \\\n",
    "             str(tool_templates) + ',' + \\\n",
    "             str(ground_templates) + ',' + \\\n",
    "             \"{:.3f}\".format(GA) + ',' + \\\n",
    "             \"{:.3f}\".format(PA) + ',' + \\\n",
    "             \"{:.3f}\".format(FGA) + ',' + \\\n",
    "             \"{:.3f}\".format(PTA) + ',' + \\\n",
    "             \"{:.3f}\".format(RTA) + ',' + \\\n",
    "             \"{:.3f}\".format(FTA) + '\\n'\n",
    "\n",
    "    with open(os.path.join(output_dir, result_file), 'a') as summary_file:\n",
    "        summary_file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File overall_evaluate.py trong Loghub 2.0\n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython import embed\n",
    "\n",
    "def evaluate(dataset, output_path, groundtruth, parsedresult, result_path):\n",
    "    \"\"\" Hàm đánh giá độ chính xác của kết quả phân tích log bằng cách so sánh với dữ liệu ground truth.\n",
    "    \n",
    "    Ghi chú:\n",
    "        - Hàm tính toán độ chính xác nhóm (GA), độ chính xác phân tích (PA), độ chính xác template (FTA, PTA, RTA).\n",
    "        - Lọc bỏ các dòng log không có `EventTemplate` trong groundtruth.\n",
    "    \n",
    "    Args:\n",
    "        dataset (str): Tên tập dữ liệu đang được đánh giá.\n",
    "        output_path (str): Thư mục chứa kết quả đầu ra.\n",
    "        groundtruth (str): Đường dẫn đến file log đã được cấu trúc hóa chuẩn (ground truth).\n",
    "        parsedresult (str): Đường dẫn đến file log đã được phân tích từ công cụ log parser.\n",
    "        result_path (str): Đường dẫn file kết quả nơi ghi lại các chỉ số đánh giá.\n",
    "\n",
    "    Returns:\n",
    "        None: Kết quả sẽ được in ra màn hình và ghi vào file `result_path`.\n",
    "\n",
    "    Examples:\n",
    "        >>> evaluate(\n",
    "            dataset='HDFS',\n",
    "            output_path='./output',\n",
    "            groundtruth='./data/HDFS/HDFS_2k_structured.csv',\n",
    "            parsedresult='./output/HDFS_2k_structured.csv',\n",
    "            result_path='./output/result.csv'\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    df_groundtruth = pd.read_csv(groundtruth)\n",
    "    df_parsedlog = pd.read_csv(parsedresult, index_col=False)\n",
    "\n",
    "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index\n",
    "    \n",
    "    df_groundtruth = df_groundtruth.loc[null_logids]\n",
    "    df_parsedlog = df_parsedlog.loc[null_logids]\n",
    "    \n",
    "    \n",
    "    GA, FGA = get_group_accuracy(df_groundtruth['EventTemplate'], df_parsedlog['EventTemplate'])\n",
    "\n",
    "    correctly_parsed_messages = df_parsedlog[['EventTemplate']].eq(df_groundtruth[['EventTemplate']]).values.sum()\n",
    "    total_messages = len(df_parsedlog[['Content']])\n",
    "\n",
    "    PA = float(correctly_parsed_messages) / total_messages\n",
    "\n",
    "    tool_templates, ground_templates, FTA, PTA, RTA = evaluate_template_level(\n",
    "        dataset=dataset,\n",
    "        groundtruth=groundtruth,\n",
    "        parsedresult=parsedresult,\n",
    "        output_dir=output_path\n",
    "    )\n",
    "\n",
    "    result = dataset + ',' + \\\n",
    "             str(tool_templates) + ',' + \\\n",
    "             str(ground_templates) + ',' + \\\n",
    "             \"{:.3f}\".format(GA) + ',' + \\\n",
    "             \"{:.3f}\".format(FGA) + ',' + \\\n",
    "             \"{:.3f}\".format(PA) + ',' + \\\n",
    "             \"{:.3f}\".format(FTA) + ',' + \\\n",
    "             \"{:.3f}\".format(PTA) + ',' + \\\n",
    "             \"{:.3f}\".format(RTA) + '\\n'\n",
    "                 \n",
    "    print(result)\n",
    "\n",
    "    with open(result_path, 'a') as summary_file:\n",
    "        summary_file.write(result)\n",
    "\n",
    "\n",
    "def get_group_accuracy(series_groundtruth, series_parsedlog, debug=False):\n",
    "    \"\"\" Đánh giá mức độ chính xác của template ở mức template-level dựa trên các kết quả phân tích đã cho, bao gồm các chỉ số FTA, PTA, RTA. Cách thực hiện tương tự như tính chỉ số GA, FGA. \n",
    "    \"\"\"\n",
    "    series_parsedlog_valuecounts = series_parsedlog.value_counts()\n",
    "    accurate_events = 0  \n",
    "    accurate_templates = 0\n",
    "\n",
    "    for parsed_eventId in series_parsedlog_valuecounts.index:\n",
    "        logIds = series_parsedlog[series_parsedlog == parsed_eventId].index\n",
    "        series_groundtruth_logId_valuecounts = series_groundtruth[logIds].value_counts()\n",
    "        error_eventIds = (parsed_eventId, series_groundtruth_logId_valuecounts.index.tolist())\n",
    "        error = True\n",
    "        if series_groundtruth_logId_valuecounts.size == 1:\n",
    "            groundtruth_eventId = series_groundtruth_logId_valuecounts.index[0]\n",
    "            if logIds.size == series_groundtruth[series_groundtruth == groundtruth_eventId].size:\n",
    "                accurate_events += logIds.size\n",
    "                accurate_templates += 1\n",
    "                error = False\n",
    "        if error and debug:\n",
    "            print('(parsed_eventId, groundtruth_eventId) =', error_eventIds, 'failed', logIds.size, 'messages')\n",
    "\n",
    "    GA = float(accurate_events) / series_groundtruth.size\n",
    "    FGA = float(accurate_templates) / len(series_groundtruth.value_counts())\n",
    "    \n",
    "    return GA, FGA\n",
    "\n",
    "\n",
    "def find_corr_oracle_templates(log_message_ids, groundtruth_df):\n",
    "    \"\"\" Tìm các template chuẩn (oracle templates) tương ứng với các dòng log được trình phân tích gán template.\n",
    "\n",
    "    Args:\n",
    "        log_message_ids (pd.DataFrame): DataFrame chứa danh sách các dòng log (theo LineId) mà công cụ log parser đã gán cùng một template.\n",
    "        groundtruth_df (pd.DataFrame): Dữ liệu ground truth đã được cấu trúc hóa, chứa thông tin chuẩn (oracle) về các dòng log và template tương ứng.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Danh sách các oracle template duy nhất tương ứng với tập các dòng log đã được parser gán cùng một template.\n",
    "\n",
    "    Examples:\n",
    "        log_message_ids:\n",
    "        +--------+\n",
    "        | LineId |\n",
    "        +--------+\n",
    "        |    1   |\n",
    "        |    3   |\n",
    "        +--------+\n",
    "\n",
    "        groundtruth_df:\n",
    "        +--------+------------------------+\n",
    "        | LineId |     EventTemplate      |\n",
    "        +--------+------------------------+\n",
    "        |    1   | Error A happened       |\n",
    "        |    2   | Disk full on node <*>  |\n",
    "        |    3   | Error A happened       |\n",
    "        +--------+------------------------+\n",
    "\n",
    "        ==> Output: [\"Error A happened\"]\n",
    "    \"\"\"\n",
    "\n",
    "    corresponding_oracle_templates = groundtruth_df.merge(log_message_ids, on='LineId')\n",
    "    corresponding_oracle_templates = list(corresponding_oracle_templates.EventTemplate.unique())\n",
    "    return corresponding_oracle_templates\n",
    "\n",
    "\n",
    "def evaluate_template_level(dataset, groundtruth, parsedresult, output_dir):\n",
    "    \"\"\" Hàm đánh giá hiệu suất phân tích log dựa trên các chỉ số: GA, PA, FTA, RTA, PTA. Đây là hàm đánh giá chung nhất, tổng quát nhất, có thể sử dụng để đánh giá cho các trình phân tích log khác nhau. Đây là tính toán theo phương thức cũ.\n",
    "    \"\"\"\n",
    "    oracle_templates = list(pd.read_csv(groundtruth)['EventTemplate'].drop_duplicates().dropna())\n",
    "    identified_templates = list(pd.read_csv(parsedresult)['EventTemplate'].drop_duplicates().dropna())\n",
    "    parsedresult_df = pd.read_csv(parsedresult)\n",
    "    groundtruth_df = pd.read_csv(groundtruth)\n",
    "\n",
    "    correct_parsing_templates = 0\n",
    "    for identified_template in identified_templates:\n",
    "\n",
    "        log_message_ids = parsedresult_df.loc[parsedresult_df['EventTemplate'] == identified_template, 'LineId']\n",
    "        log_message_ids = pd.DataFrame(log_message_ids)\n",
    "\n",
    "        corr_oracle_templates = find_corr_oracle_templates(log_message_ids, groundtruth_df)\n",
    "\n",
    "        if set(corr_oracle_templates) == {identified_template}:\n",
    "            correct_parsing_templates += 1\n",
    "            \n",
    "    PTA = correct_parsing_templates / len(identified_templates)\n",
    "    RTA = correct_parsing_templates / len(oracle_templates)\n",
    "    FTA = 0.0\n",
    "    if PTA != 0 or RTA != 0:\n",
    "        FTA = 2 * (PTA * RTA) / (PTA + RTA)\n",
    "        \n",
    "    return len(identified_templates), len(oracle_templates), FTA, PTA, RTA\n",
    "\n",
    "\n",
    "# ================================================================================\n",
    "\n",
    "\n",
    "def is_abstract(x, y):\n",
    "    if y is np.nan:\n",
    "        return False\n",
    "\n",
    "    m = re.match(get_pattern_from_template(x), y)\n",
    "    if m:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def compute_template_level_accuracy(num_oracle_template, comparison_results_df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    count_total = float(len(comparison_results_df))\n",
    "    precision = len(comparison_results_df[comparison_results_df.type == 'SM']) / count_total  # PTA\n",
    "    recall = len(comparison_results_df[comparison_results_df.type == 'SM']) / float(num_oracle_template)  # RTA\n",
    "    over_generalized = len(comparison_results_df[comparison_results_df.type == 'OG']) / count_total\n",
    "    under_generalized = len(comparison_results_df[comparison_results_df.type == 'UG']) / count_total\n",
    "    mixed = len(comparison_results_df[comparison_results_df.type == 'MX']) / count_total\n",
    "    f1_measure = 0.0\n",
    "    if precision != 0 or recall != 0:\n",
    "        f1_measure = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_measure, precision, recall, over_generalized, under_generalized, mixed\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_template_level_all(dataset, groundtruth, parsedresult, output_dir):\n",
    "    \"\"\" Thực hiện đánh giá chi tiết cấp độ mẫu (template-level evaluation) giữa các mẫu được công cụ sinh ra \n",
    "    và các mẫu gốc từ dữ liệu groundtruth.\n",
    "    Hàm phân loại từng template sinh ra từ công cụ thành các loại:\n",
    "    - SM (SaMe): Mẫu giống hệt với mẫu groundtruth tương ứng.\n",
    "    - OG (OverGeneralized): Mẫu công cụ quá trừu tượng so với mẫu gốc.\n",
    "    - UG (UnderGeneralized): Mẫu công cụ cụ thể hơn mẫu gốc.\n",
    "    - MX (MiXture): Mẫu không hoàn toàn trùng, cũng không nằm hoàn toàn trong 2 nhóm trên.\n",
    "\n",
    "    Kết quả đánh giá bao gồm:\n",
    "    - Số mẫu được công cụ sinh ra và số mẫu groundtruth.\n",
    "    - F1-measure, Precision (PTA), Recall (RTA) của mẫu công cụ.\n",
    "    - Tỷ lệ template bị phân loại là OG, UG, MX.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Tên bộ dữ liệu đang đánh giá.\n",
    "        groundtruth (str): Đường dẫn đến file CSV chứa log đã được gán nhãn (groundtruth).\n",
    "        parsedresult (str): Đường dẫn đến file CSV kết quả parser sinh ra.\n",
    "        output_dir (str): Thư mục lưu kết quả phân tích template.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int, float, float, float, float, float, float]:\n",
    "            Số mẫu công cụ sinh ra, số mẫu groundtruth,\n",
    "            F1, PTA, RTA, OG, UG, MX.\n",
    "    \"\"\"\n",
    "\n",
    "    # Đọc các mẫu gốc (groundtruth) từ file, loại bỏ mẫu rỗng và trùng lặp.\n",
    "    oracle_templates = list(pd.read_csv(groundtruth)['EventTemplate'].drop_duplicates().dropna())\n",
    "    identified_templates = list(pd.read_csv(parsedresult)['EventTemplate'].drop_duplicates().dropna())\n",
    "    parsedresult_df = pd.read_csv(parsedresult)\n",
    "    groundtruth_df = pd.read_csv(groundtruth)\n",
    "\n",
    "    comparison_results = []\n",
    "    for identified_template in identified_templates: # Lặp qua từng template công cụ sinh ra\n",
    "        identified_template_type = None\n",
    "\n",
    "        # Get the log_message_ids corresponding to the identified template from the tool-generated structured file\n",
    "        log_message_ids = parsedresult_df.loc[parsedresult_df['EventTemplate'] == identified_template, 'LineId'] # Lấy danh sách LineId (vị trí dòng log) tương ứng với template \n",
    "        log_message_ids = pd.DataFrame(log_message_ids)\n",
    "        num_messages = len(log_message_ids)\n",
    "\n",
    "        # Xác định corr_oracle_templates bằng cách sử dụng log_message_ids và oracle_structured_file\n",
    "        corr_oracle_templates = find_corr_oracle_templates(log_message_ids, groundtruth_df)\n",
    "\n",
    "        # Check SM (SaMe)\n",
    "        if set(corr_oracle_templates) == {identified_template}:\n",
    "            identified_template_type = 'SM'\n",
    "\n",
    "        # incorrect template analysis\n",
    "        if identified_template_type is None:\n",
    "\n",
    "            # determine the template type\n",
    "            template_types = set()\n",
    "            for corr_oracle_template in corr_oracle_templates:\n",
    "                if is_abstract(identified_template, corr_oracle_template):\n",
    "                    template_types.add('OG')\n",
    "                elif is_abstract(corr_oracle_template, identified_template):\n",
    "                    template_types.add('UG')\n",
    "                else:\n",
    "                    template_types.add('MX')\n",
    "\n",
    "            if len(template_types) == 1:  # if the set is singleton\n",
    "                identified_template_type = template_types.pop()\n",
    "            else:\n",
    "                identified_template_type = 'MX'\n",
    "\n",
    "        # save the results for the current identified template\n",
    "        comparison_results.append([identified_template, identified_template_type, corr_oracle_templates, num_messages])\n",
    "\n",
    "    comparison_results_df = pd.DataFrame(comparison_results,\n",
    "                                         columns=['identified_template', 'type', 'corr_oracle_templates', 'num_messages'])\n",
    "    comparison_results_df.to_csv(os.path.join(output_dir, dataset + '_template_analysis_results.csv'), index=False)\n",
    "    (F1_measure, PTA, RTA, OG, UG, MX) = compute_template_level_accuracy(len(oracle_templates), comparison_results_df)\n",
    "    print('F1: {:.4f}, PTA: {:.4f}, RTA: {:.4f}, OG: {:.4f}, UG: {:.4f}, MX: {:.4f}'.format(F1_measure, PTA, RTA, OG, UG, MX))\n",
    "    return len(identified_templates), len(oracle_templates), F1_measure, PTA, RTA, OG, UG, MX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File evaluator.py trong LogGzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.special import comb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import regex as re\n",
    "import sys\n",
    "\n",
    "\n",
    "def post_process_tokens(tokens, punc):\n",
    "    \"\"\"\n",
    "    Phương thức xử lý danh sách token để loại bỏ các ký tự không cần thiết, sau đó chuẩn hóa lại các token.\n",
    "    Cụ thể, phương thức duyệt qua từng token, nếu chứa <*>, thay thế toàn bộ bằng <*>. Sau đó, loại bỏ dấu câu được xác định trong punc trừ một số ký tự đặc biệt ['=', '|', '(', ')']. Cuối cùng, trả về danh sách token đã xử lý.\n",
    "    Args:\n",
    "        tokens (list): Danh sách các token đã được tách ra từ chuỗi đầu vào.\n",
    "        punc (str): Chuỗi chứa các ký tự được sử dụng để loại bỏ.\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các token đã được xử lý và chuẩn hóa.\n",
    "    \"\"\"\n",
    "    excluded_str = ['=', '|', '(', ')']         # Các ký tự đặc biệt không loại bỏ.\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i].find(\"<*>\") != -1:\n",
    "            tokens[i] = \"<*>\"                   # Ex: blk_<*> --> <*>\n",
    "        else:\n",
    "            # Loại bỏ các ký tự không cần thiết trong token theo danh sách punc.\n",
    "            # Default: punc = \"!\\\"#$%&'()+,-/:;=?@.[\\]^_`{|}~\"\n",
    "            new_str = \"\"\n",
    "            for s in tokens[i]:\n",
    "                if (s not in punc and s != ' ') or s in excluded_str:\n",
    "                    new_str += s\n",
    "            tokens[i] = new_str\n",
    "    return tokens\n",
    "\n",
    "def message_split(message):\n",
    "    \"\"\"\n",
    "    Chia một chuỗi đầu vào thành danh sách các token dựa trên khoảng trắng và các dấu câu đặc biệt. \n",
    "    Cụ thể, (1) Xác định các ký tự phân tách (dấu câu, khoảng trắng); (2) Sử dụng biểu thức chính quy để tách chuỗi; (3) Loại bỏ các token rỗng hoặc chỉ chứa khoảng trắng; (4)Tiền xử lý token để loại bỏ ký tự không mong muốn; (5) Xử lý trường hợp có nhiều `<*>` liên tiếp.\n",
    "    Args:\n",
    "        message (str): Chuỗi đầu vào cần tách.\n",
    "\n",
    "    Returns:\n",
    "        list: Danh sách các token sau khi tách.\n",
    "    \n",
    "    Example:\n",
    "        >>> message_split(\"Hello, world! How are you?\")\n",
    "        ['Hello', ',', 'world', '!', 'How', 'are', 'you', '?']\n",
    "    \"\"\"\n",
    "    punc = \"!\\\"#$%&'()+,-/:;=?@.[\\]^_`{|}~\"                     # Các ký tự được sử dụng để tách chuỗi.\n",
    "    splitters = \"\\s\\\\\" + \"\\\\\".join(punc)\n",
    "    splitter_regex = re.compile(\"([{}]+)\".format(splitters))    # Tạo regex để tách chuỗi, \"([{}]+)\" sẽ tìm các ký tự trong splitters và giữ chúng lại trong kết quả tách.\n",
    "    tokens = re.split(splitter_regex, message)                  # Tách chuỗi: \"Hello,,, world.. How are you?\" --> [\"Hello\", \",,,\", \"world\", \"..\", \"How\", \"are\", \"you\", \"?\"]\n",
    "    tokens = list(filter(lambda x: x != \"\", tokens))            # Loại bỏ các token rỗng.\n",
    "    tokens = post_process_tokens(tokens, punc)                  # Xử lý hậu kỳ\n",
    "    tokens = [token.strip() for token in tokens if token != \"\" and token != ' ']        # Loại bỏ các token rỗng và khoảng trắng.\n",
    "    tokens = [token for idx, token in enumerate(tokens) if not (token == \"<*>\" and idx > 0 and tokens[idx - 1] == \"<*>\")] # Loại bỏ các token \"<*>\" liên tiếp.\n",
    "    return tokens\n",
    "\n",
    "def calculate_similarity(template1, template2):\n",
    "    \"\"\"\n",
    "    Phương thức đo lường mức độ giống nhau giữa hai chuỗi văn bản (template1 và template2) bằng cách sử dụng Chỉ số Jaccard.\n",
    "    Chỉ số Jaccard là tỷ lệ giữa số lượng phần tử chung của hai tập hợp và tổng số phần tử của cả hai tập hợp.\n",
    "    \n",
    "    Args:\n",
    "        template1 (str): Chuỗi văn bản đầu tiên.\n",
    "        template2 (str): Chuỗi văn bản thứ hai. \n",
    "        \n",
    "    Returns:\n",
    "        float: Chỉ số Jaccard giữa hai chuỗi văn bản.    \n",
    "    \"\"\"\n",
    "    template1 = message_split(template1)\n",
    "    template2 = message_split(template2)\n",
    "    intersection = len(set(template1).intersection(set(template2))) # Tính số lượng phần tử chung giữa hai tập hợp.\n",
    "    union = (len(template1) + len(template2)) - intersection        # Tính tổng số phần tử của cả hai tập hợp.\n",
    "    return intersection / union\n",
    "\n",
    "def evaluate_template_level(dataset, df_groundtruth, df_parsedresult, filter_templates=None):\n",
    "    \"\"\"\n",
    "    Phương thức đánh giá chất lượng của một hệ thống trích xuất template (EventTemplate) bằng cách so sánh kết quả phân tích (df_parsedresult) với dữ liệu gốc (df_groundtruth).\n",
    "    \n",
    "    Args:\n",
    "        dataset (str): Tên của tập dữ liệu.\n",
    "        df_groundtruth (pd.DataFrame): DataFrame chứa các template gốc.\n",
    "        df_parsedresult (pd.DataFrame): DataFrame chứa các template đã được phân tích.\n",
    "        filter_templates (list, optional): Danh sách các template cần lọc. Mặc định là None.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (t1, t2, FTA, PTA, RTA), trong đó:\n",
    "            - t1 (int): Số lượng template được nhận diện.\n",
    "            - t2 (int): Số lượng template thực tế.\n",
    "            - FTA (float): F1-score của template trích xuất.\n",
    "            - PTA (float): Precision (độ chính xác) của template trích xuất.\n",
    "            - RTA (float): Recall (độ phủ) của template trích xuất.\n",
    "    \"\"\"\n",
    "    correct_parsing_templates = 0\n",
    "    if filter_templates is not None:\n",
    "        filter_identify_templates = set()        # Lưu trữ tập hợp các template được lọc (nếu có).\n",
    "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index\n",
    "    \n",
    "    # Loại bỏ các dòng có giá trị NaN trong cột EventTemplate của df_groundtruth.\n",
    "    df_groundtruth = df_groundtruth.loc[null_logids]\n",
    "    df_parsedresult = df_parsedresult.loc[null_logids]\n",
    "    \n",
    "    # Tạo các Series từ cột EventTemplate của df_groundtruth và df_parsedresult, đếm số lần xuất hiện của từng template thực tế.\n",
    "    series_groundtruth = df_groundtruth['EventTemplate']\n",
    "    series_parsedlog = df_parsedresult['EventTemplate']\n",
    "    series_groundtruth_valuecounts = series_groundtruth.value_counts()\n",
    "\n",
    "    # Gộp dữ liệu từ df_groundtruth và df_parsedresult, nhóm theo parsedlog.\n",
    "    df_combined = pd.concat([series_groundtruth, series_parsedlog], axis=1, keys=['groundtruth', 'parsedlog'])\n",
    "    grouped_df = df_combined.groupby('parsedlog')\n",
    "\n",
    "    for identified_template, group in tqdm(grouped_df):         # tqdm() thực hiện hiển thị tiến trình của vòng lặp.\n",
    "        corr_oracle_templates = set(list(group['groundtruth']))\n",
    "        if filter_templates is not None and len(corr_oracle_templates.intersection(set(filter_templates))) > 0:\n",
    "            filter_identify_templates.add(identified_template)\n",
    "\n",
    "        if corr_oracle_templates == {identified_template}:\n",
    "            if (filter_templates is None) or (identified_template in filter_templates):\n",
    "                correct_parsing_templates += 1\n",
    "\n",
    "    if filter_templates is not None:\n",
    "        PTA = correct_parsing_templates / len(filter_identify_templates)\n",
    "        RTA = correct_parsing_templates / len(filter_templates)\n",
    "    else:\n",
    "        PTA = correct_parsing_templates / len(grouped_df)\n",
    "        RTA = correct_parsing_templates / len(series_groundtruth_valuecounts)\n",
    "    FTA = 0.0\n",
    "    if PTA != 0 or RTA != 0:\n",
    "        FTA = 2 * (PTA * RTA) / (PTA + RTA)\n",
    "    print('PTA: {:.4f}, RTA: {:.4f} FTA: {:.4f}'.format(PTA, RTA, FTA))\n",
    "    t1 = len(grouped_df) if filter_templates is None else len(filter_identify_templates)\n",
    "    t2 = len(series_groundtruth_valuecounts) if filter_templates is None else len(filter_templates)\n",
    "    print(\"Identify : {}, Groundtruth : {}\".format(t1, t2))\n",
    "    return t1, t2, FTA, PTA, RTA\n",
    "\n",
    "def correct_lstm(groundtruth, parsedresult):\n",
    "    \"\"\"\n",
    "    Phương thức này kiểm tra xem hai chuỗi groundtruth (chuẩn) và parsedresult (kết quả đã phân tích) có giống nhau hay không, nhưng có một điều kiện đặc biệt: Nếu một token trong groundtruth chứa \"<*>\", thì toàn bộ token đó sẽ được thay thế bằng \"<*>\", sau đó mới so sánh hai danh sách token.\n",
    "    \n",
    "    Args:\n",
    "        groundtruth (str): Chuỗi đầu vào gốc.\n",
    "        parsedresult (str): Chuỗi đầu vào đã được phân tích.    \n",
    "    \n",
    "    Returns:\n",
    "        bool: True nếu hai chuỗi giống nhau sau khi xử lý, False nếu không.\n",
    "    \"\"\"\n",
    "    tokens1 = groundtruth.split(' ')\n",
    "    tokens2 = parsedresult.split(' ')\n",
    "    tokens1 = [\"<*>\" if \"<*>\" in token else token for token in tokens1]\n",
    "    return tokens1 == tokens2\n",
    "\n",
    "def calculate_parsing_accuracy(groundtruth_df, parsedresult_df, filter_templates=None):\n",
    "    \"\"\"\n",
    "    Phương thức tính độ chính xác của quá trình phân tích cú pháp (Parsing Accuracy - PA) dựa trên số lượng message được phân tích đúng so với tổng số message.\n",
    "    \n",
    "    Args:\n",
    "        groundtruth_df (pd.DataFrame): DataFrame chứa các template gốc.\n",
    "        parsedresult_df (pd.DataFrame): DataFrame chứa các template đã được phân tích.\n",
    "        filter_templates (list, optional): Danh sách các template cần lọc. Mặc định là None.\n",
    "        \n",
    "    Returns:\n",
    "        float: Độ chính xác của quá trình phân tích cú pháp (PA).\n",
    "    \"\"\"\n",
    "    if filter_templates is not None:\n",
    "        groundtruth_df = groundtruth_df[groundtruth_df['EventTemplate'].isin(filter_templates)]\n",
    "        parsedresult_df = parsedresult_df.loc[groundtruth_df.index]\n",
    "    correctly_parsed_messages = parsedresult_df[['EventTemplate']].eq(groundtruth_df[['EventTemplate']]).values.sum()\n",
    "    total_messages = len(parsedresult_df[['Content']])\n",
    "    PA = float(correctly_parsed_messages) / total_messages\n",
    "    print('Parsing_Accuracy (PA): {:.4f}'.format(PA))\n",
    "    return PA\n",
    "\n",
    "def calculate_parsing_accuracy_lstm(groundtruth_df, parsedresult_df, filter_templates=None):\n",
    "    \"\"\"\n",
    "    Phương thức `calculate_parsing_accuracy_lstm` được sử dụng để tính độ chính xác của việc phân tích cú pháp (Parsing Accuracy - PA) giữa dữ liệu thực tế (groundtruth_df) và dữ liệu kết quả được phân tích (parsedresult_df). Phương thức này đặc biệt sử dụng trong bối cảnh mô hình LSTM để phân tích template (Event Templates).\n",
    "    \n",
    "    Args:\n",
    "        groundtruth_df (pd.DataFrame): DataFrame chứa các template gốc.\n",
    "        parsedresult_df (pd.DataFrame): DataFrame chứa các template đã được phân tích.\n",
    "        filter_templates (list, optional): Danh sách các template cần lọc. Mặc định là None.\n",
    "        \n",
    "    Returns:\n",
    "        float: Độ chính xác của quá trình phân tích cú pháp (PA).\n",
    "    \"\"\"\n",
    "    # parsedresult_df = pd.read_csv(parsedresult)\n",
    "    # groundtruth_df = pd.read_csv(groundtruth)\n",
    "    if filter_templates is not None:\n",
    "        groundtruth_df = groundtruth_df[groundtruth_df['EventTemplate'].isin(filter_templates)]\n",
    "        parsedresult_df = parsedresult_df.loc[groundtruth_df.index]\n",
    "    # correctly_parsed_messages = parsedresult_df[['EventTemplate']].eq(groundtruth_df[['EventTemplate']]).values.sum()\n",
    "    groundtruth_templates = list(groundtruth_df['EventTemplate'])\n",
    "    parsedresult_templates = list(parsedresult_df['EventTemplate'])\n",
    "    correctly_parsed_messages = 0\n",
    "    for i in range(len(groundtruth_templates)):\n",
    "        if correct_lstm(groundtruth_templates[i], parsedresult_templates[i]):\n",
    "            correctly_parsed_messages += 1\n",
    "\n",
    "    PA = float(correctly_parsed_messages) / len(groundtruth_templates)\n",
    "\n",
    "    # similarities = []\n",
    "    # for index in range(len(groundtruth_df)):\n",
    "    #     similarities.append(calculate_similarity(groundtruth_df['EventTemplate'][index], parsedresult_df['EventTemplate'][index]))\n",
    "    # SA = sum(similarities) / len(similarities)\n",
    "    # print('Parsing_Accuracy (PA): {:.4f}, Similarity_Accuracy (SA): {:.4f}'.format(PA, SA))\n",
    "    print('Parsing_Accuracy (PA): {:.4f}'.format(PA))\n",
    "    return PA\n",
    "\n",
    "def evaluate(groundtruth, parsedresult):\n",
    "    df_groundtruth = pd.read_csv(groundtruth)\n",
    "    df_parsedlog = pd.read_csv(parsedresult)\n",
    "    \n",
    "    # Remove invalid groundtruth event Ids\n",
    "    non_empty_log_ids = df_groundtruth[~df_groundtruth[\"EventTemplate\"].isnull()].index\n",
    "    df_groundtruth = df_groundtruth.loc[non_empty_log_ids]\n",
    "    df_parsedlog = df_parsedlog.loc[non_empty_log_ids]\n",
    "\n",
    "    GA, FGA = get_accuracy(df_groundtruth[\"EventTemplate\"], df_parsedlog[\"EventTemplate\"])\n",
    "\n",
    "    accuracy_exact_string_matching = accuracy_score(\n",
    "        np.array(df_groundtruth.EventTemplate.values, dtype='str'),\n",
    "        np.array(df_parsedlog.EventTemplate.values, dtype='str')\n",
    "    )\n",
    "    # PA = calculate_parsing_accuracy_lstm(df_groundtruth, df_parsedlog)\n",
    "\n",
    "\n",
    "    _, _, FTA, PTA, RTA = evaluate_template_level(None, df_groundtruth, df_parsedlog)\n",
    "\n",
    "    print(\n",
    "        \"Grouping_Accuracy (GA): {:.4f},  FGA: {:.4f}, FTA: {:.4f}, PTA: {:.4f}, RTA: {:.4f}\".format(\n",
    "            GA, FGA, FTA, PTA, RTA\n",
    "        )\n",
    "    )\n",
    "    return GA, FGA, FTA, PTA, RTA\n",
    "\n",
    "def get_accuracy(series_groundtruth, series_parsedlog, filter_templates=None):\n",
    "    series_groundtruth_valuecounts = series_groundtruth.value_counts()\n",
    "    series_parsedlog_valuecounts = series_parsedlog.value_counts()\n",
    "    df_combined = pd.concat([series_groundtruth, series_parsedlog], axis=1, keys=['groundtruth', 'parsedlog'])\n",
    "    grouped_df = df_combined.groupby('groundtruth')\n",
    "    accurate_events = 0 # determine how many lines are correctly parsed\n",
    "    accurate_templates = 0\n",
    "    if filter_templates is not None:\n",
    "        filter_identify_templates = set()\n",
    "    for ground_truthId, group in tqdm(grouped_df):\n",
    "        series_parsedlog_logId_valuecounts = group['parsedlog'].value_counts()\n",
    "        if filter_templates is not None and ground_truthId in filter_templates:\n",
    "            for parsed_eventId in series_parsedlog_logId_valuecounts.index:\n",
    "                filter_identify_templates.add(parsed_eventId)\n",
    "        if series_parsedlog_logId_valuecounts.size == 1:\n",
    "            parsed_eventId = series_parsedlog_logId_valuecounts.index[0]\n",
    "            if len(group) == series_parsedlog[series_parsedlog == parsed_eventId].size:\n",
    "                if (filter_templates is None) or (ground_truthId in filter_templates):\n",
    "                    accurate_events += len(group)\n",
    "                    accurate_templates += 1\n",
    "    if filter_templates is not None:\n",
    "        GA = float(accurate_events) / len(series_groundtruth[series_groundtruth.isin(filter_templates)])\n",
    "        PGA = float(accurate_templates) / len(filter_identify_templates)\n",
    "        RGA = float(accurate_templates) / len(filter_templates)\n",
    "    else:\n",
    "        GA = float(accurate_events) / len(series_groundtruth)\n",
    "        PGA = float(accurate_templates) / len(series_parsedlog_valuecounts)\n",
    "        RGA = float(accurate_templates) / len(series_groundtruth_valuecounts)\n",
    "    FGA = 0.0\n",
    "    if PGA != 0 or RGA != 0:\n",
    "        FGA = 2 * (PGA * RGA) / (PGA + RGA)\n",
    "    return GA, FGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "# Copyright (C) 2016-2023 LOGPAI (https://github.com/logpai).\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =========================================================================\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from logparser.MoLFI import LogParser\n",
    "from logparser.utils import evaluator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "input_dir = \"../../data/loghub_2k/\"  # The input directory of log file\n",
    "output_dir = \"MoLFI_result/\"  # The output directory of parsing results\n",
    "\n",
    "benchmark_settings = {\n",
    "    \"HDFS\": {\n",
    "        \"log_file\": \"HDFS/HDFS_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time> <Pid> <Level> <Component>: <Content>\",\n",
    "        \"regex\": [r\"blk_-?\\d+\", r\"(\\d+\\.){3}\\d+(:\\d+)?\"],\n",
    "    },\n",
    "    \"Hadoop\": {\n",
    "        \"log_file\": \"Hadoop/Hadoop_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time> <Level> \\[<Process>\\] <Component>: <Content>\",\n",
    "        \"regex\": [r\"(\\d+\\.){3}\\d+\"],\n",
    "    },\n",
    "    \"Spark\": {\n",
    "        \"log_file\": \"Spark/Spark_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time> <Level> <Component>: <Content>\",\n",
    "        \"regex\": [r\"(\\d+\\.){3}\\d+\", r\"\\b[KGTM]?B\\b\", r\"([\\w-]+\\.){2,}[\\w-]+\"],\n",
    "    },\n",
    "    \"Zookeeper\": {\n",
    "        \"log_file\": \"Zookeeper/Zookeeper_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time> - <Level>  \\[<Node>:<Component>@<Id>\\] - <Content>\",\n",
    "        \"regex\": [r\"(/|)(\\d+\\.){3}\\d+(:\\d+)?\"],\n",
    "    },\n",
    "    \"HPC\": {\n",
    "        \"log_file\": \"HPC/HPC_2k.log\",\n",
    "        \"log_format\": \"<LogId> <Node> <Component> <State> <Time> <Flag> <Content>\",\n",
    "        \"regex\": [r\"=\\d+\"],\n",
    "    },\n",
    "    \"Thunderbird\": {\n",
    "        \"log_file\": \"Thunderbird/Thunderbird_2k.log\",\n",
    "        \"log_format\": \"<Label> <Timestamp> <Date> <User> <Month> <Day> <Time> <Location> <Component>(\\[<PID>\\])?: <Content>\",\n",
    "        \"regex\": [r\"(\\d+\\.){3}\\d+\"],\n",
    "    },\n",
    "    \"Windows\": {\n",
    "        \"log_file\": \"Windows/Windows_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time>, <Level>                  <Component>    <Content>\",\n",
    "        \"regex\": [r\"0x.*?\\s\"],\n",
    "    },\n",
    "    \"Linux\": {\n",
    "        \"log_file\": \"Linux/Linux_2k.log\",\n",
    "        \"log_format\": \"<Month> <Date> <Time> <Level> <Component>(\\[<PID>\\])?: <Content>\",\n",
    "        \"regex\": [r\"(\\d+\\.){3}\\d+\", r\"\\d{2}:\\d{2}:\\d{2}\"],\n",
    "    },\n",
    "    \"Android\": {\n",
    "        \"log_file\": \"Android/Android_2k.log\",\n",
    "        \"log_format\": \"<Date> <Time>  <Pid>  <Tid> <Level> <Component>: <Content>\",\n",
    "        \"regex\": [\n",
    "            r\"(/[\\w-]+)+\",\n",
    "            r\"([\\w-]+\\.){2,}[\\w-]+\",\n",
    "            r\"\\b(\\-?\\+?\\d+)\\b|\\b0[Xx][a-fA-F\\d]+\\b|\\b[a-fA-F\\d]{4,}\\b\",\n",
    "        ],\n",
    "    },\n",
    "    \"HealthApp\": {\n",
    "        \"log_file\": \"HealthApp/HealthApp_2k.log\",\n",
    "        \"log_format\": \"<Time>\\|<Component>\\|<Pid>\\|<Content>\",\n",
    "        \"regex\": [],\n",
    "    },\n",
    "\n",
    "    \"Proxifier\": {\n",
    "        \"log_file\": \"Proxifier/Proxifier_2k.log\",\n",
    "        \"log_format\": \"\\[<Time>\\] <Program> - <Content>\",\n",
    "        \"regex\": [\n",
    "            r\"<\\d+\\ssec\",\n",
    "            r\"([\\w-]+\\.)+[\\w-]+(:\\d+)?\",\n",
    "            r\"\\d{2}:\\d{2}(:\\d{2})*\",\n",
    "            r\"[KGTM]B\",\n",
    "        ],\n",
    "    },\n",
    "    \"OpenSSH\": {\n",
    "        \"log_file\": \"OpenSSH/OpenSSH_2k.log\",\n",
    "        \"log_format\": \"<Date> <Day> <Time> <Component> sshd\\[<Pid>\\]: <Content>\",\n",
    "        \"regex\": [r\"(\\d+\\.){3}\\d+\", r\"([\\w-]+\\.){2,}[\\w-]+\"],\n",
    "    },\n",
    "    \"OpenStack\": {\n",
    "        \"log_file\": \"OpenStack/OpenStack_2k.log\",\n",
    "        \"log_format\": \"<Logrecord> <Date> <Time> <Pid> <Level> <Component> \\[<ADDR>\\] <Content>\",\n",
    "        \"regex\": [r\"((\\d+\\.){3}\\d+,?)+\", r\"/.+?\\s\", r\"\\d+\"],\n",
    "    },\n",
    "    \"Mac\": {\n",
    "        \"log_file\": \"Mac/Mac_2k.log\",\n",
    "        \"log_format\": \"<Month>  <Date> <Time> <User> <Component>\\[<PID>\\]( \\(<Address>\\))?: <Content>\",\n",
    "        \"regex\": [r\"([\\w-]+\\.){2,}[\\w-]+\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "bechmark_result = []\n",
    "for dataset, setting in benchmark_settings.items():\n",
    "    print(\"\\n=== Evaluation on %s ===\" % dataset)\n",
    "    indir = os.path.join(input_dir, os.path.dirname(setting[\"log_file\"]))\n",
    "    log_file = os.path.basename(setting[\"log_file\"])\n",
    "\n",
    "    parser = LogParser(\n",
    "        log_format=setting[\"log_format\"],\n",
    "        indir=indir,\n",
    "        outdir=output_dir,\n",
    "        rex=setting[\"regex\"],\n",
    "    )\n",
    "    parser.parse(log_file)\n",
    "\n",
    "    F1_measure, accuracy = evaluator.evaluate(\n",
    "        groundtruth=os.path.join(indir, log_file + \"_structured.csv\"),\n",
    "        parsedresult=os.path.join(output_dir, log_file + \"_structured.csv\"),\n",
    "    )\n",
    "    bechmark_result.append([dataset, F1_measure, accuracy])\n",
    "\n",
    "print(\"\\n=== Overall evaluation results ===\")\n",
    "df_result = pd.DataFrame(bechmark_result, columns=[\"Dataset\", \"F1_measure\", \"Accuracy\"])\n",
    "df_result.set_index(\"Dataset\", inplace=True)\n",
    "print(df_result)\n",
    "df_result.to_csv(\"MoLFI_bechmark_result.csv\", float_format=\"%.6f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LOGKL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
